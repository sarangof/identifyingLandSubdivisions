{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_NAME = 'sara'\n",
    "\n",
    "AWS_PROFILE = 'cities'\n",
    "\n",
    "'''\n",
    "# List of cities to process\n",
    "cities = [\"Belo Horizonte\", \"Campinas\"]#, \"Bogota\", \"Nairobi\", \"Bamako\", \n",
    "        #\"Lagos\", \"Accra\", \"Abidjan\", \"Mogadishu\", \"Cape Town\", \n",
    "        #\"Maputo\", \"Luanda\"]\n",
    "\n",
    "test_cities = [\"Belo Horizonte\"]\n",
    "#cities = test_cities\n",
    "\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "search_buffer_files = fs.ls(SEARCH_BUFFER_PATH)\n",
    "\n",
    "cities \n",
    "\n",
    "number_of_cities = len(cities)\n",
    "\n",
    "print(f'City count: {number_of_cities}')\n",
    "'''\n",
    "grid_size = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"s3://wri-cities-sandbox/identifyingLandSubdivisions/data\"\n",
    "INPUT_PATH = f'{MAIN_PATH}/input'\n",
    "CITY_INFO_PATH = f'{INPUT_PATH}/city_info'\n",
    "EXTENTS_PATH = f'{CITY_INFO_PATH}/extents'\n",
    "BUILDINGS_PATH = f'{INPUT_PATH}/buildings'\n",
    "BLOCKS_PATH = f'{INPUT_PATH}/blocks'\n",
    "ROADS_PATH = f'{INPUT_PATH}/roads'\n",
    "INTERSECTIONS_PATH = f'{INPUT_PATH}/intersections'\n",
    "GRIDS_PATH = f'{INPUT_PATH}/city_info/grids'\n",
    "SEARCH_BUFFER_PATH = f'{INPUT_PATH}/city_info/search_buffers'\n",
    "OUTPUT_PATH = f'{MAIN_PATH}/output'\n",
    "OUTPUT_PATH_CSV = f'{OUTPUT_PATH}/csv'\n",
    "OUTPUT_PATH_RASTER = f'{OUTPUT_PATH}/raster'\n",
    "OUTPUT_PATH_PNG = f'{OUTPUT_PATH}/png'\n",
    "OUTPUT_PATH_RAW = f'{OUTPUT_PATH}/raw_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'WB1BCRT3WKRBNC18',\n",
       "  'HostId': 'elmxKwiBXoK5CqSlLGUQrJwO7ZxC0N8DZsz4E+bnX/PuEkPv8cZmz1x7IRn1cBZP2FpJv+FxOPs=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'elmxKwiBXoK5CqSlLGUQrJwO7ZxC0N8DZsz4E+bnX/PuEkPv8cZmz1x7IRn1cBZP2FpJv+FxOPs=',\n",
       "   'x-amz-request-id': 'WB1BCRT3WKRBNC18',\n",
       "   'date': 'Tue, 01 Apr 2025 21:45:34 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'aft-sandbox-540362055257',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 13, 15, 12, 20, tzinfo=tzutc())},\n",
       "  {'Name': 'amplify-citiesindicatorsapi-dev-10508-deployment',\n",
       "   'CreationDate': datetime.datetime(2023, 8, 30, 5, 5, 13, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-dev-sandbox',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 7, 23, 18, 12, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-heat',\n",
       "   'CreationDate': datetime.datetime(2023, 6, 1, 13, 22, 1, tzinfo=tzutc())},\n",
       "  {'Name': 'era5-brazil',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 15, 19, 51, 14, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-athena-us-west-2',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 12, 18, 45, 11, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-climate-hazards',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 3, 16, 57, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-data-api',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 16, 8, 53, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-heat',\n",
       "   'CreationDate': datetime.datetime(2024, 3, 25, 15, 46, 55, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-indicators',\n",
       "   'CreationDate': datetime.datetime(2024, 5, 13, 15, 50, 58, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-sandbox',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 27, 0, 51, 38, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'aws-cities',\n",
       "  'ID': 'df12253943982d72f60594f06c2cacf9a1ee3a9e738c1649c9fb96e5127f1a5c'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check s3 connection using AWS_PROFILE=CitiesUserPermissionSet profile \n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# export CitiesUserPermissionSet profile to use in the next cells\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = AWS_PROFILE\n",
    "\n",
    "\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-01 16:45:35,867][INFO    ][coiled] Fetching latest package priorities...\n",
      "[2025-04-01 16:45:35,869][INFO    ][coiled.package_sync] Resolving your local subdivisions2 Python environment...\n",
      "[2025-04-01 16:45:36,815][INFO    ][coiled.package_sync] Scanning 444 conda packages...\n",
      "[2025-04-01 16:45:36,825][INFO    ][coiled.package_sync] Scanning 259 python packages...\n",
      "[2025-04-01 16:45:37,724][INFO    ][coiled] Running pip check...\n",
      "[2025-04-01 16:45:39,290][INFO    ][coiled] Validating environment...\n",
      "[2025-04-01 16:45:41,833][INFO    ][coiled] Creating wheel for ~/Documents/Identifying Land Subdivisions/identifyingLandSubdivisions...\n",
      "[2025-04-01 16:45:42,032][WARNING ][coiled.package_sync] Package - libopenvino-intel-cpu-plugin, libopenvino-intel-cpu-plugin~=2025.0.0 has no install candidate for Python 3.12 linux-aarch64 on conda-forge\n",
      "[2025-04-01 16:45:42,033][INFO    ][coiled] Uploading coiled_local_identifyingLandSubdivisions...\n",
      "[2025-04-01 16:45:42,974][INFO    ][coiled] Requesting package sync build...\n",
      "[2025-04-01 16:45:43,847][INFO    ][coiled] Creating Cluster (name: ils-sara, https://cloud.coiled.io/clusters/818761?account=wri-cities-data ). This usually takes 1-2 minutes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a new Dask client on Coiled. Dashboard is available at https://cluster-qrnhy.dask.host/C1NczZBVgZrXV8jZ/status\n"
     ]
    }
   ],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    workspace=\"wri-cities-data\",\n",
    "    name=f'ils-{YOUR_NAME}',\n",
    "    region=\"us-west-2\",\n",
    "    arm=True,\n",
    "    worker_vm_types=\"r8g.xlarge\",\n",
    "    spot_policy=\"spot\",\n",
    "    n_workers=4,\n",
    "    package_sync_ignore=[\"pyspark\", \"pypandoc\"]\n",
    ")\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(f\"Started a new Dask client on Coiled. Dashboard is available at {client.dashboard_link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import s3fs\n",
    "import fsspec\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "search_buffer_files = fs.ls(SEARCH_BUFFER_PATH)\n",
    "\n",
    "cities = [x.split('/')[-1] for x in search_buffer_files]\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS IS PRE-PROCESSING\n",
    "'''\n",
    "\n",
    "import dask_geopandas as dgpd\n",
    "import pandas as pd\n",
    "from dask import delayed, compute, visualize\n",
    "import geopandas as gpd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from citywide_calculation import get_utm_crs\n",
    "from metrics_calculation import calculate_minimum_distance_to_roads_option_B\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "from shapely.ops import polygonize, nearest_points\n",
    "#from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, GeometryCollection\n",
    "from scipy.optimize import fminbound, minimize\n",
    "from shapely.ops import unary_union, polygonize\n",
    "import geopandas as gpd\n",
    "from polylabel import polylabel\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import mapping, Point\n",
    "from polylabel import polylabel\n",
    "\n",
    "\n",
    "@delayed\n",
    "def get_epsg(city_name):\n",
    "    search_buffer = f'{SEARCH_BUFFER_PATH}/{city_name}/{city_name}_search_buffer.geoparquet'\n",
    "    extent = dgpd.read_parquet(search_buffer)\n",
    "    geometry = extent.geometry[0].compute()\n",
    "    epsg = get_utm_crs(geometry)\n",
    "    print(f'{city_name} EPSG: {epsg}')\n",
    "    return epsg\n",
    "\n",
    "def load_dataset(path, epsg=None):\n",
    "    dataset = dgpd.read_parquet(path, npartitions=4)\n",
    "    \n",
    "    # Only assign if the file has no CRS\n",
    "    if epsg:\n",
    "        if dataset.crs is None:\n",
    "            dataset = dataset.set_crs(\"EPSG:4326\")  # assume WGS84 if missing\n",
    "        dataset = dataset.to_crs(epsg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()  \\n\\n#cities = [\\'Nairobi\\',\\'Belo_Horizonte\\']\\ncities = [\"Belo Horizonte\", \\'Nairobi\\'] #\"Campinas\", \"Bogota\", \"Nairobi\", \"Bamako\", \"Lagos\", \"Accra\", \"Abidjan\", \"Cape Town\", \"Luanda\"] #\"Maputo\",\"Mogadishu\", \\ncities = [city.replace(\\' \\', \\'_\\') for city in cities]\\n\\ntasks = [produce_blocks(city) for city in cities]\\nresults = compute(*tasks)\\n\\nend_time = time.time()  \\nelapsed_time = end_time - start_time\\n\\nprint(f\"Tasks completed in {elapsed_time:.2f} seconds.\")\\'\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def to_geojson_dict(geom):\n",
    "    \"\"\"\n",
    "    Convert a Shapely geometry to a GeoJSON-like dict with lists instead of tuples.\n",
    "    \"\"\"\n",
    "    geojson = mapping(geom)\n",
    "    def recursive_convert(obj):\n",
    "        if isinstance(obj, tuple):\n",
    "            return list(obj)\n",
    "        elif isinstance(obj, list):\n",
    "            return [recursive_convert(item) for item in obj]\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: recursive_convert(v) for k, v in obj.items()}\n",
    "        else:\n",
    "            return obj\n",
    "    return recursive_convert(geojson)\n",
    "\n",
    "def compute_largest_inscribed_circle(geom):\n",
    "    \"\"\"\n",
    "    Compute the largest inscribed circle for a given polygon or multipolygon.\n",
    "\n",
    "    Parameters:\n",
    "      geom (shapely.geometry): A Polygon or MultiPolygon.\n",
    "    \n",
    "    Returns:\n",
    "      tuple: (optimal_point, max_radius) where optimal_point is a shapely Point and max_radius is a float.\n",
    "    \"\"\"\n",
    "    if geom is None or geom.is_empty:\n",
    "        return None, None\n",
    "\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geojson_poly = to_geojson_dict(geom)\n",
    "        # Pass in the coordinates list instead of the entire dict.\n",
    "        optimal_coords = polylabel(geojson_poly[\"coordinates\"])\n",
    "        optimal = Point(optimal_coords)\n",
    "        radius = geom.boundary.distance(optimal)\n",
    "        return optimal, radius\n",
    "\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        best_point = None\n",
    "        best_radius = 0\n",
    "        for poly in geom.geoms:\n",
    "            geojson_poly = to_geojson_dict(poly)\n",
    "            optimal_coords = polylabel(geojson_poly[\"coordinates\"])\n",
    "            candidate = Point(optimal_coords)\n",
    "            radius = poly.boundary.distance(candidate)\n",
    "            if radius > best_radius:\n",
    "                best_radius = radius\n",
    "                best_point = candidate\n",
    "        return best_point, best_radius\n",
    "\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def add_inscribed_circle_info(blocks_gdf):\n",
    "    \"\"\"\n",
    "    Adds two new columns to a blocks GeoDataFrame: 'optimal_point' and 'max_radius'\n",
    "    which indicate the center and radius of the largest inscribed circle for each block.\n",
    "    Converts the optimal_point geometries to WKT strings for Parquet compatibility.\n",
    "    \n",
    "    Parameters:\n",
    "      blocks_gdf (GeoDataFrame): A GeoDataFrame with block polygons.\n",
    "      \n",
    "    Returns:\n",
    "      GeoDataFrame: The input GeoDataFrame with two new columns.\n",
    "    \"\"\"\n",
    "    # Apply the computation for each geometry\n",
    "    results = blocks_gdf.geometry.apply(lambda geom: compute_largest_inscribed_circle(geom))\n",
    "    \n",
    "    # Unpack the tuple results into two new columns\n",
    "    blocks_gdf[\"optimal_point\"] = results.apply(lambda x: x[0])\n",
    "    blocks_gdf[\"max_radius\"] = results.apply(lambda x: x[1])\n",
    "    \n",
    "    # Convert the 'optimal_point' column from Shapely objects to WKT strings\n",
    "    blocks_gdf[\"optimal_point\"] = blocks_gdf[\"optimal_point\"].apply(\n",
    "        lambda geom: geom.wkt if geom is not None else None\n",
    "    )\n",
    "    \n",
    "    return blocks_gdf\n",
    "\n",
    "\n",
    "def get_blocks(roads):\n",
    "    \"\"\"\n",
    "    Create urban blocks from a grid and road network.\n",
    "\n",
    "    Parameters:\n",
    "      grid (GeoDataFrame): A GeoDataFrame of grid polygons defining the city extent.\n",
    "      roads (GeoDataFrame): A GeoDataFrame of road line geometries.\n",
    "    \n",
    "    Returns:\n",
    "      GeoDataFrame: A GeoDataFrame of block polygons.\n",
    "    \"\"\"\n",
    "    # Merge all road geometries into a single geometry\n",
    "    roads_union = unary_union(roads.geometry)\n",
    "    \n",
    "    # Polygonize the road network to generate blocks.\n",
    "    # The polygonize function returns an iterator of Polygons.\n",
    "    blocks_polygons = list(polygonize(roads_union))\n",
    "    \n",
    "    # Create a GeoDataFrame for blocks\n",
    "    blocks_gdf = gpd.GeoDataFrame(geometry=blocks_polygons, crs=roads.crs)\n",
    "    \n",
    "    # Remove any empty geometries resulting from the intersection.\n",
    "    blocks_gdf = blocks_gdf[~blocks_gdf.is_empty]\n",
    "    \n",
    "    return blocks_gdf\n",
    "\n",
    "@delayed\n",
    "def produce_blocks(city_name):\n",
    "    # Construct file paths for the city\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'buildings': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}.geoparquet',\n",
    "        'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "        'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet'\n",
    "    }\n",
    "    \n",
    "    epsg = get_epsg(city_name)\n",
    "    \n",
    "    roads = load_dataset(paths['roads'], epsg=epsg)\n",
    "    \n",
    "    blocks = get_blocks(roads.compute())\n",
    "\n",
    "    # Now add the inscribed circle information.\n",
    "    blocks = add_inscribed_circle_info(blocks)\n",
    "    \n",
    "    # Define the output path for the blocks geoparquet\n",
    "    path_blocks = f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet'\n",
    "\n",
    "    blocks = blocks.set_crs(epsg.compute())\n",
    "\n",
    "    # Convert the geometry column to WKT before saving\n",
    "    #blocks[\"geometry\"] = blocks[\"geometry\"].apply(lambda geom: geom.wkt if geom is not None else None)\n",
    "    \n",
    "    # Save the blocks dataset. \n",
    "    blocks.to_parquet(path_blocks)\n",
    "    \n",
    "    # Optionally, return the output path or any summary info.\n",
    "    return blocks\n",
    "\n",
    "\n",
    "import time\n",
    "'''\n",
    "start_time = time.time()  \n",
    "\n",
    "#cities = ['Nairobi','Belo_Horizonte']\n",
    "cities = [\"Belo Horizonte\", 'Nairobi'] #\"Campinas\", \"Bogota\", \"Nairobi\", \"Bamako\", \"Lagos\", \"Accra\", \"Abidjan\", \"Cape Town\", \"Luanda\"] #\"Maputo\",\"Mogadishu\", \n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "tasks = [produce_blocks(city) for city in cities]\n",
    "results = compute(*tasks)\n",
    "\n",
    "end_time = time.time()  \n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Tasks completed in {elapsed_time:.2f} seconds.\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, sem, entropy\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Auxiliary functions for metric 6\n",
    "'''\n",
    "\n",
    "def calculate_standardized_kl_azimuth(buildings_df, bin_width_degrees=5):\n",
    "    azimuths = buildings_df['azimuth'].to_numpy()\n",
    "    num_bins = int(90 / bin_width_degrees)\n",
    "    histogram, _ = np.histogram(azimuths, bins=num_bins, range=(0, 90))\n",
    "    P = histogram / histogram.sum() if histogram.sum() > 0 else np.ones(num_bins) / num_bins\n",
    "    Q = np.ones(num_bins) / num_bins\n",
    "    kl_divergence = entropy(P, Q)\n",
    "    max_kl_divergence = np.log(num_bins)\n",
    "    return kl_divergence / max_kl_divergence\n",
    "\n",
    "def compute_azimuth_partition(df):\n",
    "    def azimuth(geom):\n",
    "        if geom is None or geom.is_empty:\n",
    "            return np.nan\n",
    "        oriented = geom.minimum_rotated_rectangle\n",
    "        coords = list(oriented.exterior.coords)\n",
    "        edge = LineString([coords[0], coords[1]])\n",
    "        dx, dy = edge.xy[0][1] - edge.xy[0][0], edge.xy[1][1] - edge.xy[1][0]\n",
    "        angle = np.degrees(np.arctan2(dy, dx)) % 180\n",
    "        return angle % 90\n",
    "\n",
    "    df = df.copy()\n",
    "    df['azimuth'] = df['geometry'].map(azimuth)\n",
    "    return df\n",
    "\n",
    "@delayed\n",
    "def compute_block_kl_metrics(buildings_blocks):\n",
    "    grouped = buildings_blocks.groupby('block_id')\n",
    "    kl_data = grouped.apply(lambda g: pd.Series({\n",
    "        'standardized_kl': calculate_standardized_kl_azimuth(g),\n",
    "        'n_buildings': len(g),\n",
    "    })).reset_index()\n",
    "    return kl_data\n",
    "\n",
    "def compute_block_grid_weights(blocks, grid):\n",
    "    \"\"\"\n",
    "    Computes the proportional overlap of blocks in each grid cell.\n",
    "    Returns a Dask DataFrame containing block_id, index_right (grid ID), and area_weight.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #blocks = blocks.rename_axis(index='block_id').reset_index()\n",
    "    grid = grid.rename_axis(index='grid_id').reset_index()\n",
    "\n",
    "    def overlay_partition(blocks_df, grid_df):\n",
    "        \"\"\"Computes intersection between blocks and grid.\"\"\"\n",
    "        return gpd.overlay(blocks_df, grid_df, how='intersection')\n",
    "\n",
    "    #meta = blocks._meta.merge(grid._meta, how=\"outer\")\n",
    "\n",
    "    block_grid_overlap = blocks.map_partitions(overlay_partition, grid)#, meta=meta\n",
    "\n",
    "\n",
    "    # Step 2: Compute area for each block-grid overlap\n",
    "    block_grid_overlap = block_grid_overlap.assign(\n",
    "        overlap_area=block_grid_overlap.map_partitions(lambda df: df.geometry.area, meta=('overlap_area', 'f8'))\n",
    "    )\n",
    "\n",
    "    # Step 3: Compute the total area of each grid cell\n",
    "    grid_areas = grid.assign(grid_area=grid.map_partitions(lambda df: df.geometry.area, meta=('grid_area', 'f8')))\n",
    "\n",
    "\n",
    "    # Step 4: Merge grid cell areas into block-grid overlap\n",
    "    block_grid_overlap = block_grid_overlap.merge(grid_areas[['grid_id','grid_area']], left_on='grid_id', right_on='grid_id', how='left')\n",
    "\n",
    "    # Step 5: Compute area weight as the ratio of overlap to grid cell area\n",
    "    block_grid_overlap = block_grid_overlap.assign(\n",
    "        area_weight=block_grid_overlap['overlap_area'] / block_grid_overlap['grid_area']\n",
    "    )\n",
    "    block_grid_overlap = block_grid_overlap.map_partitions(\n",
    "        lambda df: df.assign(\n",
    "            area_weight=df['area_weight'] / df.groupby(df['grid_id'])['area_weight'].transform('sum')\n",
    "        ),\n",
    "        meta=block_grid_overlap._meta  # Preserve original structure\n",
    "    )\n",
    "\n",
    "    return block_grid_overlap[['block_id', 'optimal_point', 'max_radius', 'grid_id', 'geometry', 'overlap_area', 'grid_area', 'area_weight']]\n",
    "\n",
    "\n",
    "def aggregate_m6(kl_df, overlap_df):\n",
    "    df = overlap_df.merge(kl_df, on='block_id', how='left')\n",
    "    df = df.dropna(subset=['standardized_kl'])\n",
    "\n",
    "    # Compute weights\n",
    "    df['weight'] = df['area_weight'] * df['n_buildings']\n",
    "    df['weighted_kl'] = df['standardized_kl'] * df['weight']\n",
    "\n",
    "    # Aggregate directly at the GRID level\n",
    "    grid_aggregated = df.groupby('grid_id').agg(\n",
    "        total_weighted_kl=('weighted_kl', 'sum'),\n",
    "        total_weight=('weight', 'sum')\n",
    "    )\n",
    "\n",
    "    # Compute final KL divergence for each grid cell\n",
    "    grid_aggregated['m6'] = grid_aggregated['total_weighted_kl'] / grid_aggregated['total_weight']\n",
    "\n",
    "    return grid_aggregated[['m6']]\n",
    "\n",
    "\n",
    "\n",
    "def building_orientation_metrics(city_name):\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "        'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "    }\n",
    "\n",
    "    epsg = get_epsg(city_name).compute()\n",
    "    grid = load_dataset(paths['grid'], epsg=epsg)\n",
    "    blocks = load_dataset(paths['blocks'], epsg=epsg)\n",
    "    buildings = load_dataset(paths['buildings_with_distances'], epsg=epsg)\n",
    "\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns=['geom'])\n",
    "\n",
    "    blocks['block_id'] = blocks.index\n",
    "\n",
    "    meta = buildings._meta.copy()\n",
    "    meta['azimuth'] = 'f8'\n",
    "    buildings = buildings.map_partitions(compute_azimuth_partition, meta=meta)\n",
    "\n",
    "    # Fix `sjoin` issues by computing before\n",
    "    buildings_blocks = dgpd.sjoin(buildings.compute(), blocks.compute(), predicate='intersects')\n",
    "    buildings_blocks = buildings_blocks[['block_id', 'geometry', 'azimuth']]\n",
    "\n",
    "    kl_df = compute_block_kl_metrics(buildings_blocks)\n",
    "\n",
    "    # Keep `block_grid_overlap` lazy\n",
    "    block_grid_overlap = compute_block_grid_weights(blocks, grid)\n",
    "\n",
    "    # Aggregate `m6`\n",
    "    m6_grid = aggregate_m6(kl_df.compute(), block_grid_overlap.compute())\n",
    "    grid = grid.merge(m6_grid, left_index=True, right_index=True, how='left')\n",
    "    grid['m6'] = grid['m6'].fillna(0)\n",
    "\n",
    "\n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}_metric_6.geoparquet'\n",
    "    grid.to_parquet(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas as dgpd\n",
    "import pandas as pd\n",
    "from dask import delayed, compute, visualize\n",
    "import geopandas as gpd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from citywide_calculation import get_utm_crs\n",
    "from metrics_calculation import calculate_minimum_distance_to_roads_option_B\n",
    "from shapely.geometry import MultiLineString, LineString, Point\n",
    "from shapely.ops import polygonize, nearest_points\n",
    "#from shapely.geometry import Polygon, LineString, Point, MultiPolygon, MultiLineString, GeometryCollection\n",
    "from scipy.optimize import fminbound, minimize\n",
    "import shapely.wkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport time\\n\\nstart_time = time.time()  # Start the timer\\n\\n#cities = [\\'Nairobi\\',\\'Belo_Horizonte\\']\\ncities = [\"Belo Horizonte\", \"Campinas\", \"Bogota\", \"Nairobi\", \"Bamako\", \"Lagos\", \"Accra\", \"Abidjan\", \"Cape Town\", \"Luanda\"] #\"Maputo\",\"Mogadishu\", \\ncities = [city.replace(\\' \\', \\'_\\') for city in cities]\\n\\ntasks = [block_metrics(city,YOUR_NAME,grid_size) for city in cities]\\nresults = compute(*tasks)\\n\\nend_time = time.time()  # End the timer\\nelapsed_time = end_time - start_time\\n\\nresults\\n\\nprint(f\"Tasks completed in {elapsed_time:.2f} seconds.\")\\'\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "@delayed\n",
    "def block_metrics(city_name, YOUR_NAME, grid_size):\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'buildings': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}.geoparquet',\n",
    "        'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "        'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet',\n",
    "        'blocks' : f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet'\n",
    "    }\n",
    "    # Get EPSG (you may still use a delayed get_epsg, but ensure you compute it if necessary)\n",
    "    epsg = get_epsg(city_name).compute()\n",
    "    \n",
    "    grid = load_dataset(paths['grid'], epsg=epsg)\n",
    "    blocks = load_dataset(paths['blocks'])\n",
    "\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns='geom')\n",
    "    if 'geom' in blocks.columns:\n",
    "        blocks = blocks.drop(columns='geom')\n",
    "\n",
    "    # Ensure that the active geometry is set correctly\n",
    "    grid = grid.set_geometry(\"geometry\")\n",
    "    blocks = blocks.set_geometry(\"geometry\")\n",
    "\n",
    "    grid = grid.persist()\n",
    "    blocks = blocks.persist()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    grid_sample = grid.head()\n",
    "    blocks_sample = blocks.head()\n",
    "\n",
    "    ax = grid_sample.plot(edgecolor='black', facecolor='none', figsize=(8, 8))\n",
    "    blocks_sample.plot(ax=ax, color='red', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Perform the spatial join with dask-geopandas GeoDataFrames\n",
    "    blocks_grid_joined = dgpd.sjoin(blocks, grid, predicate='intersects')\n",
    "    average_block_maxradius = blocks_grid_joined.groupby('index_right')['max_radius'].mean().astype(float)\n",
    "    \n",
    "    grid['m7'] = grid.index.map(average_block_maxradius).fillna(0).astype(float)\n",
    "    \n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}.geoparquet'\n",
    "    \n",
    "    # Remove problematic column if present\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns='geom')\n",
    "    \n",
    "    grid.to_parquet(path)\n",
    "    return path\n",
    "\n",
    "'''\n",
    "import time\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "#cities = ['Nairobi','Belo_Horizonte']\n",
    "cities = [\"Belo Horizonte\", \"Campinas\", \"Bogota\", \"Nairobi\", \"Bamako\", \"Lagos\", \"Accra\", \"Abidjan\", \"Cape Town\", \"Luanda\"] #\"Maputo\",\"Mogadishu\", \n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "tasks = [block_metrics(city,YOUR_NAME,grid_size) for city in cities]\n",
    "results = compute(*tasks)\n",
    "\n",
    "end_time = time.time()  # End the timer\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "results\n",
    "\n",
    "print(f\"Tasks completed in {elapsed_time:.2f} seconds.\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport time\\nfrom dask import compute\\n\\nstart_time = time.time()  # Start the timer\\n\\ncities = [\\'Nairobi\\']#,\\'Belo_Horizonte\\',\\'Medellin\\',\\'Bogota\\',\\'Campinas\\',\\'Luanda\\',\\'Lagos\\',\\'Cape_Town\\'\\ncities = [city.replace(\\' \\', \\'_\\') for city in cities]\\n\\ntasks = [pre_process_block_calculations(city_name, epsilon=0.001) for city_name in cities]\\nresults = compute(*tasks)  \\n\\nend_time = time.time()  # End the timer\\nelapsed_time = end_time - start_time\\n\\nprint(f\"Tasks completed in {elapsed_time:.2f} seconds.\")\\'\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_azimuths(city_name):\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "        'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "        'buildings_with_distances_azimuths': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances_and_azimuths.geoparquet',\n",
    "        'buildings_to_blocks':f'{BLOCKS_PATH}/{city_name}/{city_name}_buildings_to_blocks_{YOUR_NAME}.geoparquet'\n",
    "    }\n",
    "    epsg = get_epsg(city_name).compute()\n",
    "    buildings = load_dataset(paths['buildings_with_distances'], epsg=epsg)\n",
    "    meta = buildings._meta.copy()\n",
    "    meta['azimuth'] = 'f8'\n",
    "    buildings = buildings.map_partitions(compute_azimuth_partition, meta=meta)\n",
    "    path = paths['buildings_with_distances_azimuths']\n",
    "    buildings.to_parquet(path)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "@delayed\n",
    "def pre_process_block_calculations(city_name, epsilon):\n",
    "    calculate_azimuths(city_name)\n",
    "\n",
    "\n",
    "'''\n",
    "import time\n",
    "from dask import compute\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "cities = ['Nairobi']#,'Belo_Horizonte','Medellin','Bogota','Campinas','Luanda','Lagos','Cape_Town'\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "tasks = [pre_process_block_calculations(city_name, epsilon=0.001) for city_name in cities]\n",
    "results = compute(*tasks)  \n",
    "\n",
    "end_time = time.time()  # End the timer\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Tasks completed in {elapsed_time:.2f} seconds.\")'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks completed in 95.63 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_internal_buffer_with_target_area(geom, target_area, tolerance=1e-6, max_iter=100):\n",
    "    \"\"\"\n",
    "    Iteratively finds an internal buffer that results in the target area.\n",
    "\n",
    "    Parameters:\n",
    "    - geom: Shapely Polygon geometry.\n",
    "    - target_area: Desired area for the internal buffer.\n",
    "    - tolerance: Error tolerance for area difference.\n",
    "    - max_iter: Maximum iterations to refine buffer.\n",
    "\n",
    "    Returns:\n",
    "    - Buffered geometry (Polygon) or the original geometry if buffering is not possible.\n",
    "    \"\"\"\n",
    "    if geom.is_empty or geom.area <= target_area:\n",
    "        return geom  # Return original if no valid buffer can be made\n",
    "\n",
    "    buffer_dist = -0.1 * (geom.area ** 0.5)  # Start with a fraction of block size\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iter:\n",
    "        buffered_geom = geom.buffer(buffer_dist)\n",
    "\n",
    "        if buffered_geom.is_empty:\n",
    "            return geom  # If buffering fails, return original geometry\n",
    "\n",
    "        new_area = buffered_geom.area\n",
    "        area_diff = abs(new_area - target_area)\n",
    "\n",
    "        if area_diff < tolerance:\n",
    "            return buffered_geom  # Found a good enough buffer\n",
    "\n",
    "        # Adjust buffer distance using a binary search-like approach\n",
    "        if new_area > target_area:\n",
    "            buffer_dist *= 1.1  # Increase buffer distance\n",
    "        else:\n",
    "            buffer_dist *= 0.9  # Decrease buffer distance\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return buffered_geom  # Return best-found buffer\n",
    "\n",
    "\n",
    "\n",
    "def clip_group(df_group, buffer_type):\n",
    "    # Use the buffer from the specified column.\n",
    "    buffer_geom = df_group[buffer_type].iloc[0]\n",
    "    # Use the original building footprint column for intersection.\n",
    "    clipped = np.vectorize(lambda geom: geom.intersection(buffer_geom))(df_group['geometry'].values)\n",
    "    return pd.DataFrame({\n",
    "        'building_id': df_group['building_id'],\n",
    "        'block_id': df_group['block_id'],\n",
    "        'clipped_geometry': clipped\n",
    "    }, index=df_group.index)\n",
    "\n",
    "\n",
    "def clip_buildings_by_buffer(buildings_blocks_df, buffer_type):\n",
    "    # Copy the input and reset the index.\n",
    "    gdf = buildings_blocks_df.copy().reset_index()\n",
    "    # If an 'id' column exists, rename it; otherwise, create 'building_id' from the index.\n",
    "    if 'id' in gdf.columns:\n",
    "        gdf = gdf.rename(columns={'id': 'building_id'})\n",
    "    else:\n",
    "        gdf['building_id'] = gdf.index\n",
    "\n",
    "    if gdf.crs is None or not gdf.crs.is_projected:\n",
    "        raise ValueError(\"GeoDataFrame must have a projected CRS for efficient clipping.\")\n",
    "\n",
    "    # Group by block_id and apply the clipping function.\n",
    "    clipped_series = gdf.groupby('block_id', group_keys=False).apply(clip_group, buffer_type)\n",
    "    \n",
    "    # Create a GeoDataFrame from the result.\n",
    "    clipped_geo = gpd.GeoDataFrame(clipped_series, geometry='clipped_geometry', crs=buildings_blocks_df.crs)\n",
    "    \n",
    "    # Merge the clipped geometries back into the original GeoDataFrame.\n",
    "    gdf = gdf.merge(clipped_geo[['building_id', 'block_id', 'clipped_geometry']], \n",
    "                    on=['building_id', 'block_id'], how='left')\n",
    "    \n",
    "    gdf_clipped = gpd.GeoDataFrame(gdf.copy(), geometry='clipped_geometry', crs=buildings_blocks_df.crs)\n",
    "    gdf_clipped['clipped_area'] = gdf_clipped['clipped_geometry'].area\n",
    "    gdf_clipped['buffer_area'] = gdf_clipped[buffer_type].area\n",
    "    \n",
    "    # Aggregate the areas by block.\n",
    "    clipped_building_area = gdf_clipped.groupby('block_id')['clipped_area'].sum()\n",
    "    total_buffer_area = gdf_clipped.groupby('block_id')['buffer_area'].sum()\n",
    "    ratio = clipped_building_area / total_buffer_area\n",
    "    return ratio\n",
    "\n",
    "\n",
    "@delayed\n",
    "def compute_m6_m7_m8(city_name, YOUR_NAME, grid_size):\n",
    "    \"\"\"\n",
    "    Computes:\n",
    "    - M6: KL divergence (building orientation)\n",
    "    - M7: Average block width\n",
    "    - M8: Building density ratio (inner vs. outer buffer)\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 0.001\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "        'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "        'buildings_with_distances_azimuths': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances_and_azimuths.geoparquet',\n",
    "        'buildings_to_blocks':f'{BLOCKS_PATH}/{city_name}/{city_name}_buildings_to_blocks_{YOUR_NAME}.geoparquet'\n",
    "    }\n",
    "\n",
    "    epsg = get_epsg(city_name).compute()\n",
    "    grid = load_dataset(paths['grid'], epsg=epsg)\n",
    "    blocks = load_dataset(paths['blocks'], epsg=epsg).persist()\n",
    "    buildings = load_dataset(paths['buildings_with_distances_azimuths'], epsg=epsg).persist()\n",
    "    buildings['azimuth'] = buildings['azimuth'].map_partitions(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns=['geom'])\n",
    "    \n",
    "    blocks['block_id'] = blocks.index\n",
    "    blocks['epsilon_buffer'] = blocks['geometry'].buffer(-(1.- epsilon) * blocks['max_radius'])\n",
    "    blocks['width_buffer'] = blocks['geometry'].buffer(-0.2 * blocks['max_radius'])\n",
    "\n",
    "    buildings_blocks = dgpd.sjoin(buildings, blocks, predicate='intersects').persist() #,how='right'\n",
    "    buildings_blocks = buildings_blocks[['block_id', 'geometry', 'epsilon_buffer','width_buffer','azimuth']]\n",
    "    buildings_blocks = buildings_blocks.set_index('block_id').repartition(npartitions=4)\n",
    "\n",
    "    block_grid_overlap = compute_block_grid_weights(blocks, grid)\n",
    "    block_grid_overlap = block_grid_overlap.compute()\n",
    "\n",
    "    # Metric 6\n",
    "    kl_df = compute_block_kl_metrics(buildings_blocks)\n",
    "    m6_grid = aggregate_m6(kl_df.compute(), block_grid_overlap)\n",
    " \n",
    "    # Metric 7\n",
    "    block_grid_overlap['weighted_max_radius'] = (\n",
    "        block_grid_overlap['max_radius'] * block_grid_overlap['area_weight']\n",
    "    )\n",
    "\n",
    "    grid_m7 = block_grid_overlap.groupby('grid_id').agg(\n",
    "        total_weighted_max_radius=('weighted_max_radius', 'sum'),\n",
    "        total_weight=('area_weight', 'sum')\n",
    "    )\n",
    "    grid_m7['m7'] = grid_m7['total_weighted_max_radius'] / grid_m7['total_weight']\n",
    "\n",
    "    # Metric 8\n",
    "    width_buffer_ratios = buildings_blocks.map_partitions(clip_buildings_by_buffer, buffer_type='width_buffer')\n",
    "    epsilon_buffer_ratios = buildings_blocks.map_partitions(clip_buildings_by_buffer, buffer_type='epsilon_buffer')\n",
    "    clipped_buildings_area_to_buffer_ratio = epsilon_buffer_ratios / width_buffer_ratios\n",
    "    clipped_buildings_area_to_buffer_ratio = clipped_buildings_area_to_buffer_ratio.replace([np.inf, -np.inf], np.nan).fillna(999)\n",
    "    ratio_df = clipped_buildings_area_to_buffer_ratio.to_frame(name='m8')\n",
    "    blocks_with_m8 = blocks.merge(ratio_df, left_on='block_id', right_index=True, how='left').compute()\n",
    "    block_grid_overlap = block_grid_overlap.merge(blocks_with_m8, how='left',left_on='block_id',right_index=True)\n",
    "    block_grid_overlap['weighted_m8'] = (\n",
    "        block_grid_overlap['m8'] * block_grid_overlap['area_weight']\n",
    "    )\n",
    "    grid_m8 = block_grid_overlap.groupby('grid_id').agg(\n",
    "        total_weighted_m8=('weighted_m8', 'sum'),\n",
    "        total_weight=('area_weight', 'sum')\n",
    "    )\n",
    "    grid_m8['m8'] = grid_m8['total_weighted_m8'] / grid_m8['total_weight']\n",
    "\n",
    "    # Merge all metrics\n",
    "    grid = grid.merge(m6_grid, left_index=True, right_index=True, how='left')\n",
    "    grid = grid.merge(grid_m7[['m7']], left_index=True, right_index=True, how='left')\n",
    "    grid = grid.merge(grid_m8[['m8']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "    '''\n",
    "    # Fill NaNs\n",
    "    '''\n",
    "\n",
    "    grid['m6'] = grid['m6'].fillna(0)\n",
    "    grid['m7'] = grid['m7'].fillna(0)\n",
    "    grid['m8'] = grid['m8'].fillna(-999.)\n",
    "    \n",
    "    # Save Output\n",
    "    grid = grid.compute()  \n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}_metrics_6_7_8.geoparquet'\n",
    "    grid.to_parquet(path)\n",
    "    \n",
    "    #path = f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_with_m8_{YOUR_NAME}.geoparquet'#f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}_metrics_6_7_8.geoparquet'\n",
    "    #blocks_with_m8.to_parquet(path)\n",
    "    return  path\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from dask import compute\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "cities = ['Nairobi']\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "tasks = [compute_m6_m7_m8(city_name, YOUR_NAME, grid_size) for city_name in cities]\n",
    "results = compute(*tasks)  \n",
    "\n",
    "end_time = time.time()  # End the timer\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Tasks completed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'Nairobi'\n",
    "blocks_with_m8_0 = gpd.read_parquet(f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}_with_m8.geoparquet/part.0.parquet')\n",
    "blocks_with_m8_1 = gpd.read_parquet(f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}_with_m8.geoparquet/part.1.parquet')\n",
    "blocks_with_m8_2 = gpd.read_parquet(f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}_with_m8.geoparquet/part.2.parquet')\n",
    "blocks_with_m8_3 = gpd.read_parquet(f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}_with_m8.geoparquet/part.3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_with_m8 = results[0]\n",
    "blocks_with_m8.to_parquet('blocks_with_m8_1_minus_epsilon_0.2_max_width.geoparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>optimal_point</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>block_id</th>\n",
       "      <th>epsilon_buffer</th>\n",
       "      <th>width_buffer</th>\n",
       "      <th>m8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>POLYGON ((257194.773 9860138.634, 257242.745 9...</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "      <td>0.876002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              geometry  \\\n",
       "206  POLYGON ((257194.773 9860138.634, 257242.745 9...   \n",
       "\n",
       "                                  optimal_point  max_radius  block_id  \\\n",
       "206  POINT (257564.3624909374 9859864.43161744)   98.079789       870   \n",
       "\n",
       "                                        epsilon_buffer  \\\n",
       "206  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "\n",
       "                                          width_buffer        m8  \n",
       "206  MULTIPOLYGON (((256963.872 9860172.538, 256975...  0.876002  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_with_m8#[blocks_with_m8.block_id==870]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27564510025641265"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400462898.4840467/1452820667.2693443#blocks_with_m8.epsilon_buffer.area.sum() #334037.77896078693, 92553.75989874889, 400462898.4840467, 1452820667.2693443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'Nairobi'\n",
    "epsilon = 0.001\n",
    "\n",
    "paths = {\n",
    "    'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "    'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "    'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "    'buildings_with_distances_azimuths': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances_and_azimuths.geoparquet',\n",
    "    'buildings_to_blocks':f'{BLOCKS_PATH}/{city_name}/{city_name}_buildings_to_blocks_{YOUR_NAME}.geoparquet'\n",
    "}\n",
    "\n",
    "epsg = get_epsg(city_name).compute()\n",
    "blocks = load_dataset(paths['blocks'], epsg=epsg)\n",
    "\n",
    "blocks['block_id'] = blocks.index\n",
    "blocks['epsilon_buffer'] = blocks['geometry'].buffer(-epsilon * blocks['max_radius'])\n",
    "blocks['width_buffer'] = blocks['geometry'].buffer(-0.5 * blocks['max_radius'])\n",
    "\n",
    "blocks = blocks.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = load_dataset(paths['buildings_with_distances_azimuths'], epsg=epsg).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:3370: UserWarning: Sending large graph of size 422.07 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# After the spatial join:\n",
    "buildings_blocks = dgpd.sjoin(buildings, blocks, predicate='intersects').persist()\n",
    "#unique_blocks = buildings_blocks['block_id'].nunique().compute()\n",
    "#print(\"Unique block_ids in spatial join:\", unique_blocks)\n",
    "#print(\"Total rows in spatial join:\", len(buildings_blocks)) #Total rows in spatial join: 1570337\n",
    "#print(\"Unique block_ids in blocks:\", blocks['block_id'].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>distance_to_nearest_road</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>index_right</th>\n",
       "      <th>optimal_point</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>block_id</th>\n",
       "      <th>epsilon_buffer</th>\n",
       "      <th>width_buffer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>08b7a6e54a49bfff020004fa46fc966a</th>\n",
       "      <td>POLYGON ((248826.021 9854976.159, 248830.132 9...</td>\n",
       "      <td>16.046173476016552</td>\n",
       "      <td>55.99000353220637</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559800fff020060ce7ca2f937</th>\n",
       "      <td>POLYGON ((249449.718 9855090.983, 249447.928 9...</td>\n",
       "      <td>63.42266999571859</td>\n",
       "      <td>20.756710849882438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559801fff0200f71c799ec630</th>\n",
       "      <td>POLYGON ((249401.002 9855071.818, 249404.685 9...</td>\n",
       "      <td>102.53707652806955</td>\n",
       "      <td>21.29404677404159</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559804fff0200a57a16b4de8b</th>\n",
       "      <td>POLYGON ((249509.672 9855015.146, 249505.265 9...</td>\n",
       "      <td>115.24224541418795</td>\n",
       "      <td>25.727975833800414</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559808fff02006616fff7aaea</th>\n",
       "      <td>POLYGON ((249328.956 9855125.221, 249328.656 9...</td>\n",
       "      <td>104.09451773638028</td>\n",
       "      <td>7.0611954345631744</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559b8bfff020071c212c09e33</th>\n",
       "      <td>POLYGON ((248765.164 9855522.935, 248764.84 98...</td>\n",
       "      <td>12.262088434141244</td>\n",
       "      <td>2.736479721583123</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559b8bfff0200cd73bee6b2d7</th>\n",
       "      <td>POLYGON ((248759.767 9855524.673, 248759.068 9...</td>\n",
       "      <td>10.151673442397184</td>\n",
       "      <td>6.917151097870179</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559b8bfff0200f214206249a2</th>\n",
       "      <td>POLYGON ((248755.036 9855519.079, 248754.806 9...</td>\n",
       "      <td>17.623527537846996</td>\n",
       "      <td>4.348662893852543</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559b98fff020068e01f19e707</th>\n",
       "      <td>POLYGON ((248883.553 9855547.578, 248881.096 9...</td>\n",
       "      <td>10.327965300701207</td>\n",
       "      <td>15.600263607860128</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e559b99fff0200a62428883b20</th>\n",
       "      <td>POLYGON ((248864.919 9855533.564, 248864.663 9...</td>\n",
       "      <td>24.403269355713196</td>\n",
       "      <td>1.9787777085577574</td>\n",
       "      <td>3419</td>\n",
       "      <td>POINT (249387.8739787983 9854904.394042227)</td>\n",
       "      <td>305.13438</td>\n",
       "      <td>3419</td>\n",
       "      <td>POLYGON ((248416.393 9855128.22, 248412.677 98...</td>\n",
       "      <td>POLYGON ((248646.698 9855360.179, 248701.545 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           geometry  \\\n",
       "id                                                                                    \n",
       "08b7a6e54a49bfff020004fa46fc966a  POLYGON ((248826.021 9854976.159, 248830.132 9...   \n",
       "08b7a6e559800fff020060ce7ca2f937  POLYGON ((249449.718 9855090.983, 249447.928 9...   \n",
       "08b7a6e559801fff0200f71c799ec630  POLYGON ((249401.002 9855071.818, 249404.685 9...   \n",
       "08b7a6e559804fff0200a57a16b4de8b  POLYGON ((249509.672 9855015.146, 249505.265 9...   \n",
       "08b7a6e559808fff02006616fff7aaea  POLYGON ((249328.956 9855125.221, 249328.656 9...   \n",
       "...                                                                             ...   \n",
       "08b7a6e559b8bfff020071c212c09e33  POLYGON ((248765.164 9855522.935, 248764.84 98...   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7  POLYGON ((248759.767 9855524.673, 248759.068 9...   \n",
       "08b7a6e559b8bfff0200f214206249a2  POLYGON ((248755.036 9855519.079, 248754.806 9...   \n",
       "08b7a6e559b98fff020068e01f19e707  POLYGON ((248883.553 9855547.578, 248881.096 9...   \n",
       "08b7a6e559b99fff0200a62428883b20  POLYGON ((248864.919 9855533.564, 248864.663 9...   \n",
       "\n",
       "                                 distance_to_nearest_road             azimuth  \\\n",
       "id                                                                              \n",
       "08b7a6e54a49bfff020004fa46fc966a       16.046173476016552   55.99000353220637   \n",
       "08b7a6e559800fff020060ce7ca2f937        63.42266999571859  20.756710849882438   \n",
       "08b7a6e559801fff0200f71c799ec630       102.53707652806955   21.29404677404159   \n",
       "08b7a6e559804fff0200a57a16b4de8b       115.24224541418795  25.727975833800414   \n",
       "08b7a6e559808fff02006616fff7aaea       104.09451773638028  7.0611954345631744   \n",
       "...                                                   ...                 ...   \n",
       "08b7a6e559b8bfff020071c212c09e33       12.262088434141244   2.736479721583123   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7       10.151673442397184   6.917151097870179   \n",
       "08b7a6e559b8bfff0200f214206249a2       17.623527537846996   4.348662893852543   \n",
       "08b7a6e559b98fff020068e01f19e707       10.327965300701207  15.600263607860128   \n",
       "08b7a6e559b99fff0200a62428883b20       24.403269355713196  1.9787777085577574   \n",
       "\n",
       "                                  index_right  \\\n",
       "id                                              \n",
       "08b7a6e54a49bfff020004fa46fc966a         3419   \n",
       "08b7a6e559800fff020060ce7ca2f937         3419   \n",
       "08b7a6e559801fff0200f71c799ec630         3419   \n",
       "08b7a6e559804fff0200a57a16b4de8b         3419   \n",
       "08b7a6e559808fff02006616fff7aaea         3419   \n",
       "...                                       ...   \n",
       "08b7a6e559b8bfff020071c212c09e33         3419   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7         3419   \n",
       "08b7a6e559b8bfff0200f214206249a2         3419   \n",
       "08b7a6e559b98fff020068e01f19e707         3419   \n",
       "08b7a6e559b99fff0200a62428883b20         3419   \n",
       "\n",
       "                                                                optimal_point  \\\n",
       "id                                                                              \n",
       "08b7a6e54a49bfff020004fa46fc966a  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559800fff020060ce7ca2f937  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559801fff0200f71c799ec630  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559804fff0200a57a16b4de8b  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559808fff02006616fff7aaea  POINT (249387.8739787983 9854904.394042227)   \n",
       "...                                                                       ...   \n",
       "08b7a6e559b8bfff020071c212c09e33  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559b8bfff0200f214206249a2  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559b98fff020068e01f19e707  POINT (249387.8739787983 9854904.394042227)   \n",
       "08b7a6e559b99fff0200a62428883b20  POINT (249387.8739787983 9854904.394042227)   \n",
       "\n",
       "                                  max_radius  block_id  \\\n",
       "id                                                       \n",
       "08b7a6e54a49bfff020004fa46fc966a   305.13438      3419   \n",
       "08b7a6e559800fff020060ce7ca2f937   305.13438      3419   \n",
       "08b7a6e559801fff0200f71c799ec630   305.13438      3419   \n",
       "08b7a6e559804fff0200a57a16b4de8b   305.13438      3419   \n",
       "08b7a6e559808fff02006616fff7aaea   305.13438      3419   \n",
       "...                                      ...       ...   \n",
       "08b7a6e559b8bfff020071c212c09e33   305.13438      3419   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7   305.13438      3419   \n",
       "08b7a6e559b8bfff0200f214206249a2   305.13438      3419   \n",
       "08b7a6e559b98fff020068e01f19e707   305.13438      3419   \n",
       "08b7a6e559b99fff0200a62428883b20   305.13438      3419   \n",
       "\n",
       "                                                                     epsilon_buffer  \\\n",
       "id                                                                                    \n",
       "08b7a6e54a49bfff020004fa46fc966a  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559800fff020060ce7ca2f937  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559801fff0200f71c799ec630  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559804fff0200a57a16b4de8b  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559808fff02006616fff7aaea  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "...                                                                             ...   \n",
       "08b7a6e559b8bfff020071c212c09e33  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559b8bfff0200f214206249a2  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559b98fff020068e01f19e707  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "08b7a6e559b99fff0200a62428883b20  POLYGON ((248416.393 9855128.22, 248412.677 98...   \n",
       "\n",
       "                                                                       width_buffer  \n",
       "id                                                                                   \n",
       "08b7a6e54a49bfff020004fa46fc966a  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559800fff020060ce7ca2f937  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559801fff0200f71c799ec630  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559804fff0200a57a16b4de8b  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559808fff02006616fff7aaea  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "...                                                                             ...  \n",
       "08b7a6e559b8bfff020071c212c09e33  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559b8bfff0200cd73bee6b2d7  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559b8bfff0200f214206249a2  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559b98fff020068e01f19e707  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "08b7a6e559b99fff0200a62428883b20  POLYGON ((248646.698 9855360.179, 248701.545 9...  \n",
       "\n",
       "[108 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_blocks[buildings_blocks.block_id==3419].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>distance_to_nearest_road</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>index_right</th>\n",
       "      <th>optimal_point</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>block_id</th>\n",
       "      <th>epsilon_buffer</th>\n",
       "      <th>width_buffer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>08b7a6e428000fff02003fb9f2cb81fd</th>\n",
       "      <td>POLYGON ((257165.429 9860043.549, 257135.451 9...</td>\n",
       "      <td>3.5902859944719845</td>\n",
       "      <td>60.62048095338031</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428002fff02002e46dd39bd05</th>\n",
       "      <td>POLYGON ((257175.202 9860056.266, 257163.065 9...</td>\n",
       "      <td>0.7550096264179459</td>\n",
       "      <td>65.78024821038267</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428002fff02003cbf3f5cf6f5</th>\n",
       "      <td>POLYGON ((257173.459 9860093.183, 257168.468 9...</td>\n",
       "      <td>3.374771804109713</td>\n",
       "      <td>63.92829133524706</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428002fff0200488fe729c9ae</th>\n",
       "      <td>POLYGON ((257159.757 9860063.929, 257142.875 9...</td>\n",
       "      <td>11.992409414033153</td>\n",
       "      <td>66.88616716020653</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428002fff02004e659355c6b6</th>\n",
       "      <td>POLYGON ((257162.19 9860079.43, 257151.948 986...</td>\n",
       "      <td>5.38941016386697</td>\n",
       "      <td>60.61944580119112</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428c59fff0200b5b62804e36f</th>\n",
       "      <td>POLYGON ((257599.018 9859831.84, 257599.533 98...</td>\n",
       "      <td>20.220089944953344</td>\n",
       "      <td>80.91694312126168</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428c59fff0200d6591ce878bf</th>\n",
       "      <td>POLYGON ((257609.275 9859827.278, 257580.107 9...</td>\n",
       "      <td>4.479492589701704</td>\n",
       "      <td>80.0712280288098</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428c59fff0200e9b0cb2f5c9e</th>\n",
       "      <td>POLYGON ((257624.146 9859824.046, 257609.168 9...</td>\n",
       "      <td>8.881326207001798</td>\n",
       "      <td>80.0712280482829</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428c5afff020042287780c1f7</th>\n",
       "      <td>POLYGON ((257680.404 9859896.748, 257645.274 9...</td>\n",
       "      <td>19.972523541085707</td>\n",
       "      <td>38.33536019773507</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08b7a6e428c5bfff0200be0c3b1797f9</th>\n",
       "      <td>POLYGON ((257602.668 9859837.805, 257612.008 9...</td>\n",
       "      <td>14.316828366532418</td>\n",
       "      <td>57.30793932485621</td>\n",
       "      <td>870</td>\n",
       "      <td>POINT (257564.3624909374 9859864.43161744)</td>\n",
       "      <td>98.079789</td>\n",
       "      <td>870</td>\n",
       "      <td>POLYGON ((257194.725 9860138.548, 257242.697 9...</td>\n",
       "      <td>MULTIPOLYGON (((256963.872 9860172.538, 256975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           geometry  \\\n",
       "id                                                                                    \n",
       "08b7a6e428000fff02003fb9f2cb81fd  POLYGON ((257165.429 9860043.549, 257135.451 9...   \n",
       "08b7a6e428002fff02002e46dd39bd05  POLYGON ((257175.202 9860056.266, 257163.065 9...   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5  POLYGON ((257173.459 9860093.183, 257168.468 9...   \n",
       "08b7a6e428002fff0200488fe729c9ae  POLYGON ((257159.757 9860063.929, 257142.875 9...   \n",
       "08b7a6e428002fff02004e659355c6b6  POLYGON ((257162.19 9860079.43, 257151.948 986...   \n",
       "...                                                                             ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f  POLYGON ((257599.018 9859831.84, 257599.533 98...   \n",
       "08b7a6e428c59fff0200d6591ce878bf  POLYGON ((257609.275 9859827.278, 257580.107 9...   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e  POLYGON ((257624.146 9859824.046, 257609.168 9...   \n",
       "08b7a6e428c5afff020042287780c1f7  POLYGON ((257680.404 9859896.748, 257645.274 9...   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9  POLYGON ((257602.668 9859837.805, 257612.008 9...   \n",
       "\n",
       "                                 distance_to_nearest_road            azimuth  \\\n",
       "id                                                                             \n",
       "08b7a6e428000fff02003fb9f2cb81fd       3.5902859944719845  60.62048095338031   \n",
       "08b7a6e428002fff02002e46dd39bd05       0.7550096264179459  65.78024821038267   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5        3.374771804109713  63.92829133524706   \n",
       "08b7a6e428002fff0200488fe729c9ae       11.992409414033153  66.88616716020653   \n",
       "08b7a6e428002fff02004e659355c6b6         5.38941016386697  60.61944580119112   \n",
       "...                                                   ...                ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f       20.220089944953344  80.91694312126168   \n",
       "08b7a6e428c59fff0200d6591ce878bf        4.479492589701704   80.0712280288098   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e        8.881326207001798   80.0712280482829   \n",
       "08b7a6e428c5afff020042287780c1f7       19.972523541085707  38.33536019773507   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9       14.316828366532418  57.30793932485621   \n",
       "\n",
       "                                  index_right  \\\n",
       "id                                              \n",
       "08b7a6e428000fff02003fb9f2cb81fd          870   \n",
       "08b7a6e428002fff02002e46dd39bd05          870   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5          870   \n",
       "08b7a6e428002fff0200488fe729c9ae          870   \n",
       "08b7a6e428002fff02004e659355c6b6          870   \n",
       "...                                       ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f          870   \n",
       "08b7a6e428c59fff0200d6591ce878bf          870   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e          870   \n",
       "08b7a6e428c5afff020042287780c1f7          870   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9          870   \n",
       "\n",
       "                                                               optimal_point  \\\n",
       "id                                                                             \n",
       "08b7a6e428000fff02003fb9f2cb81fd  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428002fff02002e46dd39bd05  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428002fff0200488fe729c9ae  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428002fff02004e659355c6b6  POINT (257564.3624909374 9859864.43161744)   \n",
       "...                                                                      ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428c59fff0200d6591ce878bf  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428c5afff020042287780c1f7  POINT (257564.3624909374 9859864.43161744)   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9  POINT (257564.3624909374 9859864.43161744)   \n",
       "\n",
       "                                  max_radius  block_id  \\\n",
       "id                                                       \n",
       "08b7a6e428000fff02003fb9f2cb81fd   98.079789       870   \n",
       "08b7a6e428002fff02002e46dd39bd05   98.079789       870   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5   98.079789       870   \n",
       "08b7a6e428002fff0200488fe729c9ae   98.079789       870   \n",
       "08b7a6e428002fff02004e659355c6b6   98.079789       870   \n",
       "...                                      ...       ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f   98.079789       870   \n",
       "08b7a6e428c59fff0200d6591ce878bf   98.079789       870   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e   98.079789       870   \n",
       "08b7a6e428c5afff020042287780c1f7   98.079789       870   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9   98.079789       870   \n",
       "\n",
       "                                                                     epsilon_buffer  \\\n",
       "id                                                                                    \n",
       "08b7a6e428000fff02003fb9f2cb81fd  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428002fff02002e46dd39bd05  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428002fff02003cbf3f5cf6f5  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428002fff0200488fe729c9ae  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428002fff02004e659355c6b6  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "...                                                                             ...   \n",
       "08b7a6e428c59fff0200b5b62804e36f  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428c59fff0200d6591ce878bf  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428c5afff020042287780c1f7  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "08b7a6e428c5bfff0200be0c3b1797f9  POLYGON ((257194.725 9860138.548, 257242.697 9...   \n",
       "\n",
       "                                                                       width_buffer  \n",
       "id                                                                                   \n",
       "08b7a6e428000fff02003fb9f2cb81fd  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428002fff02002e46dd39bd05  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428002fff02003cbf3f5cf6f5  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428002fff0200488fe729c9ae  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428002fff02004e659355c6b6  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "...                                                                             ...  \n",
       "08b7a6e428c59fff0200b5b62804e36f  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428c59fff0200d6591ce878bf  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428c59fff0200e9b0cb2f5c9e  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428c5afff020042287780c1f7  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "08b7a6e428c5bfff0200be0c3b1797f9  MULTIPOLYGON (((256963.872 9860172.538, 256975...  \n",
       "\n",
       "[189 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_blocks[buildings_blocks.block_id==870].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks missing: 7323\n",
      "                                             geometry  \\\n",
      "6   POLYGON ((267359.786 9850914.292, 267281.122 9...   \n",
      "16  POLYGON ((255229.229 9856779.139, 255238.28 98...   \n",
      "20  POLYGON ((255758.391 9857820.393, 255745.934 9...   \n",
      "22  POLYGON ((255678.593 9857700.421, 255672.491 9...   \n",
      "27  POLYGON ((256642.416 9857463.434, 256733.748 9...   \n",
      "\n",
      "                                   optimal_point  max_radius  block_id  \\\n",
      "6   POINT (266979.35204538767 9850991.086018158)   98.278196         6   \n",
      "16  POINT (255238.51091183256 9856754.831162918)    5.679321        16   \n",
      "20  POINT (255694.80285892845 9857718.934448328)   23.049142        20   \n",
      "22  POINT (255537.24405270943 9857593.153526023)    8.997523        22   \n",
      "27   POINT (257097.0789480702 9857679.317723105)    7.314309        27   \n",
      "\n",
      "                                       epsilon_buffer  \\\n",
      "6   POLYGON ((267359.757 9850914.386, 267281.102 9...   \n",
      "16  POLYGON ((255229.239 9856779.116, 255238.275 9...   \n",
      "20  POLYGON ((255758.371 9857820.405, 255758.37 98...   \n",
      "22  POLYGON ((255678.556 9857700.442, 255672.494 9...   \n",
      "27  POLYGON ((256642.419 9857463.427, 256733.751 9...   \n",
      "\n",
      "                                         width_buffer  \n",
      "6   POLYGON ((266884.08 9851077.96, 266916.086 985...  \n",
      "16  POLYGON ((255234.282 9856767.568, 255235.888 9...  \n",
      "20  POLYGON ((255676.35 9857717.408, 255678.527 98...  \n",
      "22  POLYGON ((255504.252 9857587.925, 255511.664 9...  \n",
      "27  POLYGON ((256644.041 9857460.155, 256735.267 9...  \n"
     ]
    }
   ],
   "source": [
    "blocks_id_set = set(blocks['block_id'])\n",
    "bblocks_id_set = set(buildings_blocks['block_id'])\n",
    "\n",
    "# Get the IDs that are in blocks but NOT in buildings_blocks\n",
    "missing_block_ids = blocks_id_set - bblocks_id_set\n",
    "\n",
    "# Filter blocks to those IDs\n",
    "missing_blocks = blocks[blocks['block_id'].isin(missing_block_ids)]\n",
    "\n",
    "print(f\"Number of blocks missing: {len(missing_blocks)}\")\n",
    "print(missing_blocks.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_blocks = dgpd.sjoin(buildings, blocks, predicate='intersects')\n",
    "buildings_blocks = buildings_blocks[['block_id', 'geometry', 'epsilon_buffer','width_buffer','azimuth']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/3n9j2kc92kv4psztx687vtd80000gn/T/ipykernel_6841/1509015195.py:37: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  area_df = gdf.groupby('block_id', group_keys=False).apply(clip_group_area_temporary, buffer_type)\n",
      "/var/folders/mt/3n9j2kc92kv4psztx687vtd80000gn/T/ipykernel_6841/1509015195.py:37: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  area_df = gdf.groupby('block_id', group_keys=False).apply(clip_group_area_temporary, buffer_type)\n",
      "/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:3370: UserWarning: Sending large graph of size 422.08 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "P2P 5d26a429c1e56c52542e2f1cb8ecdcfc failed during transfer phase",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_core.py:523\u001b[0m, in \u001b[0;36mhandle_transfer_errors\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_shuffle.py:57\u001b[0m, in \u001b[0;36mshuffle_transfer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_worker_plugin.py:349\u001b[0m, in \u001b[0;36madd_partition\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_core.py:367\u001b[0m, in \u001b[0;36madd_partition\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_shuffle.py:286\u001b[0m, in \u001b[0;36m_shard_partition\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_shuffle.py:104\u001b[0m, in \u001b[0;36msplit_by_worker\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/dask/utils.py:772\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/dask/dataframe/backends.py:223\u001b[0m, in \u001b[0;36mget_pyarrow_table_from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/table.pxi:3874\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3873\u001b[0m from pyarrow.pandas_compat import dataframe_to_arrays\n\u001b[0;32m-> 3874\u001b[0m arrays, schema, n_rows = dataframe_to_arrays(\n\u001b[1;32m   3875\u001b[0m     df,\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mconvert_column\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mconvert_column\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/array.pxi:339\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m         values, obj.dtype, type)\n\u001b[0;32m--> 339\u001b[0m result = _ndarray_to_array(values, mask, type, c_from_pandas, safe,\n\u001b[1;32m    340\u001b[0m                            pool)\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/array.pxi:81\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m shared_ptr[CChunkedArray] chunked_out\n\u001b[0;32m---> 81\u001b[0m shared_ptr[CDataType] c_type = _ndarray_to_type(values, type)\n\u001b[1;32m     82\u001b[0m CCastOptions cast_options = CCastOptions(safe)\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/array.pxi:69\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m if type is None and dtype != object:\n\u001b[0;32m---> 69\u001b[0m     c_type = GetResultValue(NumPyDtypeToArrow(dtype))\n\u001b[1;32m     70\u001b[0m \n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     except -1 nogil:\n\u001b[0;32m--> 154\u001b[0m return check_status(status)\n\u001b[1;32m    155\u001b[0m \n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m---> 91\u001b[0m         raise convert_status(status)\n\u001b[1;32m     92\u001b[0m \n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column geometry with type geometry')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m width_buffer_ratios \u001b[38;5;241m=\u001b[39m clip_buildings_by_buffer_temporary(buildings_blocks, buffer_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m epsilon_buffer_ratios \u001b[38;5;241m=\u001b[39m clip_buildings_by_buffer_temporary(buildings_blocks, buffer_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m width_buffer_ratios \u001b[38;5;241m=\u001b[39m \u001b[43mwidth_buffer_ratios\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m epsilon_buffer_ratios \u001b[38;5;241m=\u001b[39m epsilon_buffer_ratios\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/dataframe/dask_expr/_collection.py:489\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    488\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/dask/dataframe/dask_expr/_shuffle.py:548\u001b[0m, in \u001b[0;36m_shuffle_transfer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_shuffle.py:56\u001b[0m, in \u001b[0;36mshuffle_transfer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m__exit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.12/site-packages/distributed/shuffle/_core.py:531\u001b[0m, in \u001b[0;36mhandle_transfer_errors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: P2P 5d26a429c1e56c52542e2f1cb8ecdcfc failed during transfer phase"
     ]
    }
   ],
   "source": [
    "def clip_group_area_temporary(df_group, buffer_type):\n",
    "    \"\"\"\n",
    "    For each group (block), compute the intersection of the building footprints\n",
    "    with the specified buffer and return the area of the intersection (clipped area)\n",
    "    along with the area of the buffer.\n",
    "    \"\"\"\n",
    "    # Get the buffer geometry for this group (assumed constant within group)\n",
    "    buffer_geom = df_group[buffer_type].iloc[0]\n",
    "    # Compute the intersection of each building footprint with the buffer\n",
    "    intersections = np.vectorize(lambda geom: geom.intersection(buffer_geom))(df_group['geometry'].values)\n",
    "    # Compute area for each intersection; if None, use 0\n",
    "    clipped_areas = [inter.area if inter is not None else 0.0 for inter in intersections]\n",
    "    # Assume buffer area is constant across the group; compute it once\n",
    "    buf_area = buffer_geom.area\n",
    "    # Create a DataFrame of results (only numeric columns)\n",
    "    return pd.DataFrame({\n",
    "        'block_id': df_group['block_id'],\n",
    "        'clipped_area': clipped_areas,\n",
    "        'buffer_area': [buf_area] * len(df_group)\n",
    "    }, index=df_group.index)\n",
    "\n",
    "\n",
    "def clip_buildings_by_buffer_temporary(buildings_blocks_df, buffer_type):\n",
    "    \"\"\"\n",
    "    Instead of returning geometries, this function returns the ratio of the total\n",
    "    clipped building area to the total buffer area for each block.\n",
    "    \"\"\"\n",
    "    gdf = buildings_blocks_df.copy().reset_index(drop=True)\n",
    "    # Ensure we have a 'block_id' column and a 'building_id' column\n",
    "    if 'id' in gdf.columns:\n",
    "        gdf = gdf.rename(columns={'id': 'building_id'})\n",
    "    else:\n",
    "        gdf['building_id'] = gdf.index\n",
    "\n",
    "    # We assume that gdf already has the proper CRS\n",
    "    # Use groupby-apply with our new function that computes areas\n",
    "    area_df = gdf.groupby('block_id', group_keys=False).apply(clip_group_area_temporary, buffer_type)\n",
    "    \n",
    "    # Aggregate the results for each block\n",
    "    total_clipped_area = area_df.groupby('block_id')['clipped_area'].sum()\n",
    "    total_buffer_area = area_df.groupby('block_id')['buffer_area'].sum()\n",
    "    \n",
    "    # Compute the ratio (using division that produces NaN if buffer area is 0)\n",
    "    ratio = total_clipped_area / total_buffer_area\n",
    "    return ratio\n",
    "\n",
    "\n",
    "width_buffer_ratios = clip_buildings_by_buffer_temporary(buildings_blocks, buffer_type='width_buffer')\n",
    "epsilon_buffer_ratios = clip_buildings_by_buffer_temporary(buildings_blocks, buffer_type='epsilon_buffer')\n",
    "\n",
    "width_buffer_ratios = width_buffer_ratios.compute()\n",
    "epsilon_buffer_ratios = epsilon_buffer_ratios.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask-GeoPandas GeoDataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>epsilon_buffer</th>\n",
       "      <th>width_buffer</th>\n",
       "      <th>azimuth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: getitem, 2 expressions</div>"
      ],
      "text/plain": [
       "Dask GeoDataFrame Structure:\n",
       "              block_id  geometry epsilon_buffer width_buffer azimuth\n",
       "npartitions=1                                                       \n",
       "                 int64  geometry       geometry     geometry  string\n",
       "                   ...       ...            ...          ...     ...\n",
       "Dask Name: getitem, 2 expressions\n",
       "Expr=FromGraph(8050434)[['block_id', 'geometry', 'epsilon_buffer', 'width_buffer', 'azimuth']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique block_ids in spatial join: <dask_expr.expr.Scalar: expr=(DropDuplicates(frame=(FromGraph(8050434)[['block_id', 'geometry', 'epsilon_buffer', 'width_buffer', 'azimuth']])['block_id'], split_every=False, shuffle_method='p2p')).count(), dtype=int64>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:3370: UserWarning: Sending large graph of size 422.07 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique block_ids in spatial join:\u001b[39m\u001b[38;5;124m\"\u001b[39m, buildings_blocks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique())\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rows in spatial join:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuildings_blocks\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/dataframe/dask_expr/_collection.py:389\u001b[0m, in \u001b[0;36mFrameBase.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/dataframe/dask_expr/_collection.py:489\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    488\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/subdivisions2/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Unique block_ids in spatial join:\", buildings_blocks['block_id'].nunique())\n",
    "print(\"Total rows in spatial join:\", len(buildings_blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "clipped_buildings_area_to_buffer_ratio = epsilon_buffer_ratios / width_buffer_ratios\n",
    "\n",
    "clipped_buildings_area_to_buffer_ratio = clipped_buildings_area_to_buffer_ratio.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Convert the ratio to a DataFrame (if it's not already)\n",
    "ratio_df = clipped_buildings_area_to_buffer_ratio.to_frame(name='m8')\n",
    "\n",
    "# Merge it into the blocks GeoDataFrame using the block_id index.\n",
    "#blocks_with_m8 = blocks.merge(ratio_df, left_on='block_id', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.393200e+04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_buildings_area_to_buffer_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocks_with_m8 = blocks_with_m8.merge(gpd.GeoDataFrame(width_buffer_ratios,columns=['width_buffer_ratio']),left_on='block_id',right_index=True)\n",
    "blocks_with_m8.to_parquet('blocks_with_width_buffer_ratio.geoparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_with_m8['width_buffer_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'Nairobi'\n",
    "blocks_with_m8 = results[0].set_geometry('geometry')\n",
    "blocks_with_m8.to_parquet(f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}_with_m8.geoparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subdivisions2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
