{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City count: 2\n"
     ]
    }
   ],
   "source": [
    "YOUR_NAME = 'sara'\n",
    "\n",
    "AWS_PROFILE = 'cities'\n",
    "\n",
    "\n",
    "# List of cities to process\n",
    "cities = [\"Belo Horizonte\", \"Campinas\"]#, \"Bogota\", \"Nairobi\", \"Bamako\", \n",
    "        #\"Lagos\", \"Accra\", \"Abidjan\", \"Mogadishu\", \"Cape Town\", \n",
    "        #\"Maputo\", \"Luanda\"]\n",
    "\n",
    "test_cities = [\"Belo Horizonte\"]\n",
    "#cities = test_cities\n",
    "\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "number_of_cities = len(cities)\n",
    "\n",
    "print(f'City count: {number_of_cities}')\n",
    "\n",
    "grid_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"s3://wri-cities-sandbox/identifyingLandSubdivisions/data\"\n",
    "INPUT_PATH = f'{MAIN_PATH}/input'\n",
    "CITY_INFO_PATH = f'{INPUT_PATH}/city_info'\n",
    "EXTENTS_PATH = f'{CITY_INFO_PATH}/extents'\n",
    "BUILDINGS_PATH = f'{INPUT_PATH}/buildings'\n",
    "ROADS_PATH = f'{INPUT_PATH}/roads'\n",
    "INTERSECTIONS_PATH = f'{INPUT_PATH}/intersections'\n",
    "GRIDS_PATH = f'{INPUT_PATH}/city_info/grids'\n",
    "OUTPUT_PATH = f'{MAIN_PATH}/output'\n",
    "OUTPUT_PATH_CSV = f'{OUTPUT_PATH}/csv'\n",
    "OUTPUT_PATH_RASTER = f'{OUTPUT_PATH}/raster'\n",
    "OUTPUT_PATH_PNG = f'{OUTPUT_PATH}/png'\n",
    "OUTPUT_PATH_RAW = f'{OUTPUT_PATH}/raw_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '84D0VZQXMNNH8VGM',\n",
       "  'HostId': 'DoXW6EGTqv5ba58XwqnhtTHqv19ug2orpSejR+2E9PpNXfON3yJTbaASMExWAHlzTv5u9w4skhc=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'DoXW6EGTqv5ba58XwqnhtTHqv19ug2orpSejR+2E9PpNXfON3yJTbaASMExWAHlzTv5u9w4skhc=',\n",
       "   'x-amz-request-id': '84D0VZQXMNNH8VGM',\n",
       "   'date': 'Wed, 12 Mar 2025 03:29:02 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'aft-sandbox-540362055257',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 13, 15, 12, 20, tzinfo=tzutc())},\n",
       "  {'Name': 'amplify-citiesindicatorsapi-dev-10508-deployment',\n",
       "   'CreationDate': datetime.datetime(2023, 8, 30, 5, 5, 13, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-dev-sandbox',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 7, 23, 18, 12, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-heat',\n",
       "   'CreationDate': datetime.datetime(2023, 6, 1, 13, 22, 1, tzinfo=tzutc())},\n",
       "  {'Name': 'era5-brazil',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 15, 19, 51, 14, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-athena-us-west-2',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 12, 18, 45, 11, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-climate-hazards',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 3, 16, 57, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-data-api',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 16, 8, 53, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-heat',\n",
       "   'CreationDate': datetime.datetime(2024, 3, 25, 15, 46, 55, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-indicators',\n",
       "   'CreationDate': datetime.datetime(2024, 5, 13, 15, 50, 58, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-sandbox',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 27, 0, 51, 38, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'aws-cities',\n",
       "  'ID': 'df12253943982d72f60594f06c2cacf9a1ee3a9e738c1649c9fb96e5127f1a5c'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check s3 connection using AWS_PROFILE=CitiesUserPermissionSet profile \n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# export CitiesUserPermissionSet profile to use in the next cells\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = AWS_PROFILE\n",
    "\n",
    "\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-11 22:29:04,732][INFO    ][coiled] Using existing cluster: 'ils-sara (id: 793315)'\n",
      "[2025-03-11 22:29:04,734][INFO    ][coiled] Attaching to existing cluster (name: ils-sara, https://cloud.coiled.io/clusters/793315?account=wri-cities-data )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a new Dask client on Coiled. Dashboard is available at https://cluster-tuirq.dask.host/C5sf1UxHnJ4evFtP/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-35' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "2025-03-12 07:53:34,483 - distributed.deploy.cluster - WARNING - Failed to sync cluster info multiple times - perhaps there's a connection issue? Error:\n",
      "TimeoutError: [Errno 60] Operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/utils.py\", line 1910, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 560, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TLSConnector object at 0x14a849550>: TimeoutError: [Errno 60] Operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/deploy/cluster.py\", line 165, in _sync_cluster_info\n",
      "    await self.scheduler_comm.set_metadata(\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/core.py\", line 1176, in send_recv_from_rpc\n",
      "    comm = await self.live_comm()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/core.py\", line 1135, in live_comm\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/comm/core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tls://54.202.65.89:443 after 30 s\n"
     ]
    }
   ],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    workspace=\"wri-cities-data\",\n",
    "    name=f'ils-{YOUR_NAME}',\n",
    "    region=\"us-west-2\",\n",
    "    arm=True,\n",
    "    worker_vm_types=\"r8g.xlarge\",\n",
    "    spot_policy=\"spot\",\n",
    "    n_workers=4,\n",
    ")\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(f\"Started a new Dask client on Coiled. Dashboard is available at {client.dashboard_link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas as dgpd\n",
    "from dask import delayed, compute, visualize\n",
    "from dask.diagnostics import ProgressBar\n",
    "%autoreload\n",
    "from citywide_calculation import get_utm_crs\n",
    "from metrics_calculation import calculate_minimum_distance_to_roads_option_B\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "\n",
    "@delayed\n",
    "def get_epsg(city_name):\n",
    "    urban_extent = f'{EXTENTS_PATH}/{city_name}/{city_name}_urban_extent.geoparquet'\n",
    "    extent = dgpd.read_parquet(urban_extent)\n",
    "    geometry = extent.geometry[0].compute()\n",
    "    epsg = get_utm_crs(geometry)\n",
    "    print(f'{city_name} EPSG: {epsg}')\n",
    "    return epsg\n",
    "\n",
    "@delayed\n",
    "def load_dataset(path, epsg=None):\n",
    "    \"\"\"Load a single parquet dataset\"\"\"\n",
    "    dataset = dgpd.read_parquet(path, npartitions=2)\n",
    "    if epsg:\n",
    "        dataset = dataset.to_crs(epsg=epsg)\n",
    "    return dataset\n",
    "\n",
    "@delayed\n",
    "def row_count(dgdf):\n",
    "    \"\"\"Count the rows in a dataframe\"\"\"\n",
    "    row_count = dgdf.map_partitions(len).compute().sum()\n",
    "\n",
    "    return row_count\n",
    "\n",
    "\n",
    "def test_math(input):\n",
    "    return input + input\n",
    "\n",
    "%autoreload\n",
    "from metrics_groupby import metrics\n",
    "\n",
    "@delayed\n",
    "def metrics(city_name,YOUR_NAME,grid_size):\n",
    "    grid_cell_count = 0\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'buildings': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}.geoparquet',\n",
    "        'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "        'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet'\n",
    "    }\n",
    "    # Get EPSG\n",
    "    epsg = get_epsg(city_name)\n",
    "    # Load grid\n",
    "    grid = load_dataset(paths['grid'], epsg=epsg).compute()\n",
    "    grid['cell_area'] = grid.geometry.area\n",
    "\n",
    "    cells = grid.index.size\n",
    "    grid_cell_count += cells.compute()\n",
    "\n",
    "    # Load buildings and perform relevant calculations on it\n",
    "    buildings = load_dataset(paths['buildings'], epsg=epsg).compute()\n",
    "    buildings['area'] = buildings.geometry.area\n",
    "    joined_buildings = dgpd.sjoin(buildings, grid, predicate='within')  \n",
    "    counts_buildings = joined_buildings.groupby('index_right').size()\n",
    "    grid['n_buildings'] = grid.index.map(counts_buildings).fillna(0).astype(int)\n",
    "    built_area_buildings = joined_buildings.groupby('index_right')['area'].sum()\n",
    "    grid['built_area'] = grid.index.map(built_area_buildings).fillna(0).astype(float)\n",
    "\n",
    "    #total_buildings = row_count(buildings).compute()\n",
    "    #print(total_buildings)\n",
    "    # Load roads\n",
    "    #roads = load_dataset(paths['roads'], epsg=epsg).compute()\n",
    "    #road_union = roads.unary_union.compute()\n",
    "    # Load intersections\n",
    "    intersections = load_dataset(paths['intersections'], epsg=epsg).compute()\n",
    "    print(type(intersections))\n",
    "    intersections_3plus = intersections[intersections.street_count >= 3]\n",
    "    print(type(intersections_3plus))\n",
    "    intersections_4way = intersections[intersections.street_count == 4]\n",
    "    print(type(intersections_4way))\n",
    "\n",
    "    '''\n",
    "    buildings['distance_to_road'] = buildings['geometry'].map_partitions(\n",
    "        lambda partition: partition.apply(lambda geom: calculate_minimum_distance_to_roads_option_B(geom, road_union)),\n",
    "        meta=('distance_to_road', 'float64')\n",
    "    )\n",
    "    \n",
    "    buildings_within_10m_of_buildings = buildings[buildings.distance_to_road <= 20]\n",
    "    joined_buildings_within_10m_of_buildings = dgpd.sjoin(buildings_within_10m_of_buildings, grid, predicate='within')\n",
    "    counts_buildings_within_10m_of_buildings = joined_buildings_within_10m_of_buildings.groupby('index_right').size()\n",
    "    grid['n_buildings_within_10m_of_roads'] = grid.index.map(counts_buildings_within_10m_of_buildings).fillna(0).astype(int)\n",
    "    joined_buildings_distance_to_road = dgpd.sjoin(buildings[['geometry', 'distance_to_road']], grid, predicate='within')\n",
    "    # NOT SURE OF THIS YET\n",
    "    averaged_buildings_distance_to_road = joined_buildings_distance_to_road.groupby('index_right')['distance_to_road'].mean()\n",
    "    grid['average_distance_to_closest_roads'] = grid.index.map(averaged_buildings_distance_to_road).fillna(0).astype(int)\n",
    "    '''\n",
    "    joined_intersections_3plus = dgpd.sjoin(intersections_3plus, grid, predicate='within')\n",
    "    counts_intersections_3plus = joined_intersections_3plus.groupby('index_right').size()\n",
    "    grid['intersections_3plus'] = grid.index.map(counts_intersections_3plus).fillna(0).astype(int)\n",
    "\n",
    "    joined_intersections_4way = dgpd.sjoin(intersections_4way, grid, predicate='within')\n",
    "    counts_intersections_4way = joined_intersections_4way.groupby('index_right').size()\n",
    "    grid['intersections_4way'] = grid.index.map(counts_intersections_4way).fillna(0).astype(int)\n",
    "    \n",
    "    '''\n",
    "    grid['m1'] = grid['n_buildings_within_10m_of_roads'] / grid['n_buildings']\n",
    "    grid['m2'] = grid['average_distance_to_closest_roads']\n",
    "    '''\n",
    "\n",
    "    grid['m4'] = grid['intersections_4way'] / grid['intersections_3plus']\n",
    "\n",
    "\n",
    "    grid['m11'] = 1.0*grid['n_buildings'] / grid['cell_area'] # Building density\n",
    "    grid['m12'] = grid['built_area'] / grid['cell_area'] # Built area share\n",
    "    grid['m13'] = grid['built_area'] / grid['n_buildings'] # Average building area\n",
    "\n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}.geoparquet'\n",
    "    grid.to_parquet(path)\n",
    "    return grid_cell_count, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belo_Horizonte', 'Campinas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30188,\n",
       "  's3://wri-cities-sandbox/identifyingLandSubdivisions/data/output/raster/Belo_Horizonte/Belo_Horizonte_200m_grid_sara.geoparquet'),\n",
       " (37752,\n",
       "  's3://wri-cities-sandbox/identifyingLandSubdivisions/data/output/raster/Campinas/Campinas_200m_grid_sara.geoparquet'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cities)\n",
    "\n",
    "# Create delayed tasks for counting\n",
    "grid_calculations = []\n",
    "\n",
    "for city_name in cities:\n",
    "    grid_calc = metrics(city_name, YOUR_NAME, grid_size=grid_size)\n",
    "    grid_calculations.append(grid_calc)\n",
    "\n",
    "#visualize(*grid_calulations)\n",
    "calculated_grids = compute(*grid_calculations)\n",
    "calculated_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grid cells: 462160\n"
     ]
    }
   ],
   "source": [
    "# Sum the total number of grid cells\n",
    "total_grid_cells = sum([grid_cells for grid_cells, path in calculated_grids])\n",
    "print(f'Total grid cells: {total_grid_cells}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subdivisions2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
