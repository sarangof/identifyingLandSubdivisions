{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_NAME = 'sara'\n",
    "\n",
    "AWS_PROFILE = 'cities'\n",
    "\n",
    "'''\n",
    "# List of cities to process\n",
    "cities = [\"Belo Horizonte\", \"Campinas\"]#, \"Bogota\", \"Nairobi\", \"Bamako\", \n",
    "        #\"Lagos\", \"Accra\", \"Abidjan\", \"Mogadishu\", \"Cape Town\", \n",
    "        #\"Maputo\", \"Luanda\"]\n",
    "\n",
    "test_cities = [\"Belo Horizonte\"]\n",
    "#cities = test_cities\n",
    "\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "search_buffer_files = fs.ls(SEARCH_BUFFER_PATH)\n",
    "\n",
    "cities \n",
    "\n",
    "number_of_cities = len(cities)\n",
    "\n",
    "print(f'City count: {number_of_cities}')\n",
    "'''\n",
    "grid_size = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"s3://wri-cities-sandbox/identifyingLandSubdivisions/data\"\n",
    "INPUT_PATH = f'{MAIN_PATH}/input'\n",
    "CITY_INFO_PATH = f'{INPUT_PATH}/city_info'\n",
    "EXTENTS_PATH = f'{CITY_INFO_PATH}/extents'\n",
    "BUILDINGS_PATH = f'{INPUT_PATH}/buildings'\n",
    "BLOCKS_PATH = f'{INPUT_PATH}/blocks'\n",
    "ROADS_PATH = f'{INPUT_PATH}/roads'\n",
    "INTERSECTIONS_PATH = f'{INPUT_PATH}/intersections'\n",
    "GRIDS_PATH = f'{INPUT_PATH}/city_info/grids'\n",
    "SEARCH_BUFFER_PATH = f'{INPUT_PATH}/city_info/search_buffers'\n",
    "OUTPUT_PATH = f'{MAIN_PATH}/output'\n",
    "OUTPUT_PATH_CSV = f'{OUTPUT_PATH}/csv'\n",
    "OUTPUT_PATH_RASTER = f'{OUTPUT_PATH}/raster'\n",
    "OUTPUT_PATH_PNG = f'{OUTPUT_PATH}/png'\n",
    "OUTPUT_PATH_RAW = f'{OUTPUT_PATH}/raw_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '689WEDWQ67PBGCB2',\n",
       "  'HostId': 'HXQCZFoh+H+/ZQmgHu/c3fawzLM+o1/mX9sWKdF2DHhm7vOQuHA8UmOtvqSMDR5P/YxPE+2v48g=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'HXQCZFoh+H+/ZQmgHu/c3fawzLM+o1/mX9sWKdF2DHhm7vOQuHA8UmOtvqSMDR5P/YxPE+2v48g=',\n",
       "   'x-amz-request-id': '689WEDWQ67PBGCB2',\n",
       "   'date': 'Sun, 30 Mar 2025 04:10:48 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'aft-sandbox-540362055257',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 13, 15, 12, 20, tzinfo=tzutc())},\n",
       "  {'Name': 'amplify-citiesindicatorsapi-dev-10508-deployment',\n",
       "   'CreationDate': datetime.datetime(2023, 8, 30, 5, 5, 13, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-dev-sandbox',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 7, 23, 18, 12, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-heat',\n",
       "   'CreationDate': datetime.datetime(2023, 6, 1, 13, 22, 1, tzinfo=tzutc())},\n",
       "  {'Name': 'era5-brazil',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 15, 19, 51, 14, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-athena-us-west-2',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 12, 18, 45, 11, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-climate-hazards',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 3, 16, 57, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-data-api',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 16, 8, 53, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-heat',\n",
       "   'CreationDate': datetime.datetime(2024, 3, 25, 15, 46, 55, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-indicators',\n",
       "   'CreationDate': datetime.datetime(2024, 5, 13, 15, 50, 58, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-sandbox',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 27, 0, 51, 38, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'aws-cities',\n",
       "  'ID': 'df12253943982d72f60594f06c2cacf9a1ee3a9e738c1649c9fb96e5127f1a5c'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check s3 connection using AWS_PROFILE=CitiesUserPermissionSet profile \n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# export CitiesUserPermissionSet profile to use in the next cells\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = AWS_PROFILE\n",
    "\n",
    "\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-29 23:10:50,294][INFO    ][coiled] Fetching latest package priorities...\n",
      "[2025-03-29 23:10:50,295][INFO    ][coiled.package_sync] Resolving your local subdivisions2 Python environment...\n",
      "[2025-03-29 23:10:51,158][INFO    ][coiled.package_sync] Scanning 444 conda packages...\n",
      "[2025-03-29 23:10:51,166][INFO    ][coiled.package_sync] Scanning 259 python packages...\n",
      "[2025-03-29 23:10:52,173][INFO    ][coiled] Running pip check...\n",
      "[2025-03-29 23:10:54,158][INFO    ][coiled] Validating environment...\n",
      "[2025-03-29 23:10:56,359][INFO    ][coiled] Creating wheel for ~/Documents/Identifying Land Subdivisions/identifyingLandSubdivisions...\n",
      "[2025-03-29 23:10:56,672][WARNING ][coiled.package_sync] Package - libopenvino-intel-cpu-plugin, libopenvino-intel-cpu-plugin~=2025.0.0 has no install candidate for Python 3.12 linux-aarch64 on conda-forge\n",
      "[2025-03-29 23:10:56,682][INFO    ][coiled] Uploading coiled_local_identifyingLandSubdivisions...\n",
      "[2025-03-29 23:10:57,613][INFO    ][coiled] Requesting package sync build...\n",
      "[2025-03-29 23:10:58,394][INFO    ][coiled] Creating Cluster (name: ils-sara, https://cloud.coiled.io/clusters/814934?account=wri-cities-data ). This usually takes 1-2 minutes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a new Dask client on Coiled. Dashboard is available at https://cluster-mceib.dask.host/s-8rZ2K9so1ysToQ/status\n"
     ]
    }
   ],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    workspace=\"wri-cities-data\",\n",
    "    name=f'ils-{YOUR_NAME}',\n",
    "    region=\"us-west-2\",\n",
    "    arm=True,\n",
    "    worker_vm_types=\"r8g.xlarge\",\n",
    "    spot_policy=\"spot\",\n",
    "    n_workers=8,\n",
    "    package_sync_ignore=[\"pyspark\", \"pypandoc\"]\n",
    ")\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(f\"Started a new Dask client on Coiled. Dashboard is available at {client.dashboard_link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import s3fs\n",
    "import fsspec\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "search_buffer_files = fs.ls(SEARCH_BUFFER_PATH)\n",
    "\n",
    "cities = [x.split('/')[-1] for x in search_buffer_files]\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dgpd\n",
    "from dask import delayed, compute, visualize\n",
    "from citywide_calculation import get_utm_crs\n",
    "\n",
    "@delayed\n",
    "def get_epsg(city_name):\n",
    "    search_buffer = f'{SEARCH_BUFFER_PATH}/{city_name}/{city_name}_search_buffer.geoparquet'\n",
    "    extent = dgpd.read_parquet(search_buffer)\n",
    "    geometry = extent.geometry[0].compute()\n",
    "    epsg = get_utm_crs(geometry)\n",
    "    print(f'{city_name} EPSG: {epsg}')\n",
    "    return epsg\n",
    "\n",
    "def load_dataset(path, epsg=None):\n",
    "    dataset = dgpd.read_parquet(path, npartitions=4)\n",
    "    \n",
    "    # Only assign if the file has no CRS\n",
    "    if epsg:\n",
    "        if dataset.crs is None:\n",
    "            dataset = dataset.set_crs(\"EPSG:4326\")  # assume WGS84 if missing\n",
    "        dataset = dataset.to_crs(epsg)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks completed in 21.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Step 1: Compute Bearings Vectorized ---\n",
    "\n",
    "def compute_bearing_vectorized(x1, y1, x2, y2):\n",
    "    \"\"\"Compute bearing (in degrees) from (x1,y1) to (x2,y2) in vectorized form.\"\"\"\n",
    "    # Compute differences\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    angles_rad = np.arctan2(dy, dx)\n",
    "    angles_deg = np.degrees(angles_rad) % 360\n",
    "    return angles_deg\n",
    "\n",
    "def compute_intersection_angles(roads_df, intersections_df):\n",
    "    \"\"\"\n",
    "    For each road, compute the bearing at the intersection.\n",
    "    \n",
    "    For each road, we assume:\n",
    "      - If an intersection is the start (u), we compute the bearing from that intersection\n",
    "        (using its coordinates from intersections_df) to the road's centroid.\n",
    "      - Similarly for the end (v).\n",
    "    \n",
    "    Returns a DataFrame with columns:\n",
    "      intersection_id, bearing\n",
    "    \"\"\"\n",
    "    # Merge for start intersections\n",
    "    roads_u = roads_df.merge(intersections_df[['osmid', 'geometry']], left_on='u', right_on='osmid', how='left', suffixes=('', '_u'))\n",
    "    # Extract coordinates: intersection (start) and road centroid\n",
    "    roads_u['x_u'] = roads_u.geometry_u.x\n",
    "    roads_u['y_u'] = roads_u.geometry_u.y\n",
    "    roads_u['centroid_x'] = roads_u.geometry.centroid.x\n",
    "    roads_u['centroid_y'] = roads_u.geometry.centroid.y\n",
    "    roads_u['bearing'] = compute_bearing_vectorized(roads_u['x_u'], roads_u['y_u'],\n",
    "                                                      roads_u['centroid_x'], roads_u['centroid_y'])\n",
    "    roads_u = roads_u[['u', 'bearing']].rename(columns={'u': 'intersection_id'})\n",
    "    \n",
    "    # Merge for end intersections\n",
    "    roads_v = roads_df.merge(intersections_df[['osmid', 'geometry']], left_on='v', right_on='osmid', how='left', suffixes=('', '_v'))\n",
    "    roads_v['x_v'] = roads_v.geometry_v.x\n",
    "    roads_v['y_v'] = roads_v.geometry_v.y\n",
    "    roads_v['centroid_x'] = roads_v.geometry.centroid.x\n",
    "    roads_v['centroid_y'] = roads_v.geometry.centroid.y\n",
    "    roads_v['bearing'] = compute_bearing_vectorized(roads_v['x_v'], roads_v['y_v'],\n",
    "                                                      roads_v['centroid_x'], roads_v['centroid_y'])\n",
    "    roads_v = roads_v[['v', 'bearing']].rename(columns={'v': 'intersection_id'})\n",
    "    \n",
    "    # Combine both: Each row corresponds to a road connected to an intersection, with its computed bearing.\n",
    "    intersection_angles = dd.concat([roads_u, roads_v], interleave_partitions=True)\n",
    "    return intersection_angles\n",
    "\n",
    "# --- Step 2: Compute Sequential Differences for Each Intersection ---\n",
    "\n",
    "\n",
    "def compute_sequential_differences(angles):\n",
    "    \"\"\"\n",
    "    Given a sorted array of angles (in degrees), compute the circular differences\n",
    "    between consecutive angles (including the wrap-around).\n",
    "    \"\"\"\n",
    "    # Append the first angle plus 360 to account for wrap-around\n",
    "    extended = np.concatenate([angles, [angles[0] + 360]])\n",
    "    return np.diff(extended)\n",
    "\n",
    "def compute_intersection_metric(group, street_count_mapping):\n",
    "    \"\"\"\n",
    "    Computes the metric for one intersection.\n",
    "    \n",
    "    Parameters:\n",
    "      group: DataFrame group (with a column 'bearing') for a given intersection.\n",
    "      street_count_mapping: dict mapping intersection_id to its street_count.\n",
    "      \n",
    "    Process:\n",
    "      1. Get the unique bearings (the \"true\" angles).\n",
    "      2. Use the provided street_count (if available) to confirm the number of unique angles.\n",
    "      3. Sort the unique angles and compute the circular differences.\n",
    "      4. For 3‑way intersections (street_count==3): select the smallest difference.\n",
    "         For 4‑way intersections (street_count==4): select the two smallest differences and average them.\n",
    "      5. Compute the absolute difference between the selected value(s) and 90°.\n",
    "    \"\"\"\n",
    "    inter_id = group.name  # group name is the intersection_id\n",
    "    # Get expected street count for this intersection\n",
    "    expected_sc = street_count_mapping.get(inter_id, None)\n",
    "    \n",
    "    # Deduplicate angles\n",
    "    unique_angles = np.unique(group['bearing'].values)\n",
    "    sc = len(unique_angles)\n",
    "    \n",
    "    # If we have an expected street count, use that if possible.\n",
    "    # (It might differ if data are noisy.)\n",
    "    if expected_sc is not None and expected_sc in (3, 4):\n",
    "        sc = expected_sc\n",
    "    else:\n",
    "        # Only process intersections with 3 or 4 unique angles\n",
    "        if sc not in (3, 4):\n",
    "            return np.nan\n",
    "\n",
    "    # Ensure we have exactly sc unique angles\n",
    "    angles = np.sort(unique_angles)\n",
    "    \n",
    "    # Compute circular differences\n",
    "    diffs = compute_sequential_differences(angles)\n",
    "    \n",
    "    if sc == 3:\n",
    "        # For a 3-way, select the smallest difference\n",
    "        selected_diff = np.min(diffs)\n",
    "        metric = abs(90 - selected_diff)\n",
    "    elif sc == 4:\n",
    "        # For a 4-way, select the two smallest differences and average the absolute differences from 90°\n",
    "        selected_diffs = np.sort(diffs)[:2]\n",
    "        metric = np.mean(np.abs(90 - selected_diffs))\n",
    "    else:\n",
    "        metric = np.nan\n",
    "    \n",
    "    return metric\n",
    "\n",
    "\n",
    "def compute_intersection_mapping(intersection_angles, street_count_mapping):\n",
    "    \"\"\"\n",
    "    Given a DataFrame 'intersection_angles' with columns ['intersection_id', 'bearing'],\n",
    "    group by intersection_id and compute the metric using the known street counts.\n",
    "    Returns a Series mapping intersection_id to the computed metric.\n",
    "    \"\"\"\n",
    "    # Group by intersection_id and apply the metric function.\n",
    "    mapping = intersection_angles.groupby('intersection_id').apply(\n",
    "        lambda grp: compute_intersection_metric(grp, street_count_mapping)\n",
    "    )\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def calculate_tortuosity(roads_df, intersections_df):\n",
    "\n",
    "    # Merge roads with intersections for start point (u)\n",
    "    roads_with_start = roads_df.merge(\n",
    "        intersections_df[['osmid', 'geometry']],\n",
    "        left_on='u',\n",
    "        right_on='osmid',\n",
    "        how='left',\n",
    "        suffixes=('', '_start')\n",
    "    )\n",
    "\n",
    "    # Merge with intersections again for end point (v)\n",
    "    roads_with_both = roads_with_start.merge(\n",
    "        intersections_df[['osmid', 'geometry']],\n",
    "        left_on='v',\n",
    "        right_on='osmid',\n",
    "        how='left',\n",
    "        suffixes=('', '_end')\n",
    "    )\n",
    "\n",
    "    # Rename the merged geometry columns for clarity\n",
    "    roads_with_both = roads_with_both.rename(\n",
    "        columns={'geometry': 'road_geometry',\n",
    "                'geometry_start': 'start_geom',\n",
    "                'geometry_end': 'end_geom'}\n",
    "    )\n",
    "\n",
    "    # --- Step 2: Compute Straight-Line Distance between Intersections ---\n",
    "\n",
    "    # Use the .distance method from GeoPandas (this assumes a projected CRS)\n",
    "    roads_with_both['straight_distance'] = roads_with_both.apply(\n",
    "        lambda row: row['start_geom'].distance(row['end_geom']), axis=1\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Compute Road Length (if not already present) ---\n",
    "\n",
    "    if 'length' not in roads_with_both.columns:\n",
    "        roads_with_both['length'] = roads_with_both['road_geometry'].length\n",
    "\n",
    "    # --- Step 4: Compute Tortuosity ---\n",
    "    # Tortuosity is defined as road_length divided by the straight-line distance.\n",
    "    # To avoid division by zero, we use np.where to set tortuosity to NaN when straight_distance is 0.\n",
    "\n",
    "    roads_with_both['tortuosity'] = np.where(\n",
    "        roads_with_both['straight_distance'] > 0,\n",
    "        roads_with_both['straight_distance']/ roads_with_both['length'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    return roads_with_both\n",
    "\n",
    "\n",
    "def metrics_roads_intersections(city_name):\n",
    "\n",
    "    paths = {\n",
    "    'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "    'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "    'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "    'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "    'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet'\n",
    "    }\n",
    "\n",
    "    epsg = get_epsg(city_name).compute()\n",
    "    grid = load_dataset(paths['grid'], epsg=epsg)\n",
    "    roads = load_dataset(paths['roads'], epsg=epsg)\n",
    "    intersections = load_dataset(paths['intersections'], epsg=epsg).compute()\n",
    "\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns=['geom'])\n",
    "\n",
    "    intersections['osmid'] = intersections['osmid'].astype(int)\n",
    "    intersection_angles = compute_intersection_angles(roads, intersections)\n",
    "    street_count_mapping = intersections.set_index('osmid')['street_count'].to_dict()\n",
    "    intersection_angle_mapping = compute_intersection_mapping(intersection_angles, street_count_mapping)\n",
    "    intersection_angle_mapping = intersection_angle_mapping.compute()  \n",
    "\n",
    "\n",
    "    intersections_with_angles_metric = intersections.merge(\n",
    "        intersection_angle_mapping.rename(\"average_angle\"), left_on=\"osmid\", right_index=True, how=\"left\"\n",
    "    )\n",
    "\n",
    "    joined_intersection_angles_grid = dgpd.sjoin(intersections_with_angles_metric, grid, predicate=\"within\")\n",
    "    average_angle_between_roads = joined_intersection_angles_grid.groupby('index_right')['average_angle'].mean()\n",
    "\n",
    "\n",
    "    roads_with_tortuosity = calculate_tortuosity(roads.compute(), intersections)\n",
    "    joined_tortuosity_grid = dgpd.sjoin(roads_with_tortuosity.set_geometry('road_geometry'), grid, predicate=\"within\")\n",
    "    average_tortuosity = joined_tortuosity_grid.groupby('index_right')['tortuosity'].mean()\n",
    "\n",
    "\n",
    "    grid['metric_9'] = grid.index.map(average_tortuosity).fillna(-999.).astype(float)\n",
    "    grid['metric_10'] = grid.index.map(average_angle_between_roads).fillna(-999.).astype(float)\n",
    "\n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_metrics_9_10_{YOUR_NAME}.geoparquet'\n",
    "\n",
    "    if 'geom' in grid.columns:\n",
    "        grid = grid.drop(columns='geom')\n",
    "\n",
    "    grid.to_parquet(path)\n",
    "\n",
    "    return path\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "import time\n",
    "start_time = time.time()  \n",
    "\n",
    "cities = ['Nairobi']\n",
    "\n",
    "tasks = [delayed(metrics_roads_intersections)(city) for city in cities]\n",
    "\n",
    "results = compute(*tasks)\n",
    "\n",
    "end_time = time.time()  \n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Tasks completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(mapping.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/3n9j2kc92kv4psztx687vtd80000gn/T/ipykernel_76178/2723016076.py:121: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  mapping = intersection_angles.groupby('intersection_id').apply(\n"
     ]
    }
   ],
   "source": [
    "city_name = 'Nairobi'\n",
    "\n",
    "paths = {\n",
    "'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "'blocks': f'{BLOCKS_PATH}/{city_name}/{city_name}_blocks_{YOUR_NAME}.geoparquet',\n",
    "'buildings_with_distances': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}_with_distances.geoparquet',\n",
    "'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet'\n",
    "}\n",
    "\n",
    "epsg = get_epsg(city_name).compute()\n",
    "grid = load_dataset(paths['grid'], epsg=epsg)\n",
    "roads = load_dataset(paths['roads'], epsg=epsg)\n",
    "intersections = load_dataset(paths['intersections'], epsg=epsg).compute()\n",
    "\n",
    "if 'geom' in grid.columns:\n",
    "    grid = grid.drop(columns=['geom'])\n",
    "\n",
    "intersections['osmid'] = intersections['osmid'].astype(int)\n",
    "intersection_angles = compute_intersection_angles(roads, intersections)\n",
    "street_count_mapping = intersections.set_index('osmid')['street_count'].to_dict()\n",
    "intersection_angle_mapping = compute_intersection_mapping(intersection_angles, street_count_mapping)\n",
    "intersection_angle_mapping = intersection_angle_mapping.compute()  \n",
    "\n",
    "\n",
    "intersections_with_angles_metric = intersections.merge(\n",
    "    intersection_angle_mapping.rename(\"average_angle\"), left_on=\"osmid\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "joined_intersection_angles_grid = dgpd.sjoin(intersections_with_angles_metric, grid, predicate=\"within\")\n",
    "average_angle_between_roads = joined_intersection_angles_grid.groupby('index_right')['average_angle'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_with_angles_metric.to_parquet('intersections_with_angles.geoparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    320224.000000\n",
      "mean          0.965383\n",
      "std           0.092962\n",
      "min           0.007647\n",
      "25%           0.991078\n",
      "50%           0.996044\n",
      "75%           0.999557\n",
      "max           1.001610\n",
      "Name: tortuosity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "intersections_df['osmid'] = intersections_df['osmid'].astype('int')\n",
    "\n",
    "def calculate_tortuosity(roads_df, intersections_df):\n",
    "\n",
    "    # Merge roads with intersections for start point (u)\n",
    "    roads_with_start = roads_df.merge(\n",
    "        intersections_df[['osmid', 'geometry']],\n",
    "        left_on='u',\n",
    "        right_on='osmid',\n",
    "        how='left',\n",
    "        suffixes=('', '_start')\n",
    "    )\n",
    "\n",
    "    # Merge with intersections again for end point (v)\n",
    "    roads_with_both = roads_with_start.merge(\n",
    "        intersections_df[['osmid', 'geometry']],\n",
    "        left_on='v',\n",
    "        right_on='osmid',\n",
    "        how='left',\n",
    "        suffixes=('', '_end')\n",
    "    )\n",
    "\n",
    "    # Rename the merged geometry columns for clarity\n",
    "    roads_with_both = roads_with_both.rename(\n",
    "        columns={'geometry': 'road_geometry',\n",
    "                'geometry_start': 'start_geom',\n",
    "                'geometry_end': 'end_geom'}\n",
    "    )\n",
    "\n",
    "    # --- Step 2: Compute Straight-Line Distance between Intersections ---\n",
    "\n",
    "    # Use the .distance method from GeoPandas (this assumes a projected CRS)\n",
    "    roads_with_both['straight_distance'] = roads_with_both.apply(\n",
    "        lambda row: row['start_geom'].distance(row['end_geom']), axis=1\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Compute Road Length (if not already present) ---\n",
    "\n",
    "    if 'length' not in roads_with_both.columns:\n",
    "        roads_with_both['length'] = roads_with_both['road_geometry'].length\n",
    "\n",
    "    # --- Step 4: Compute Tortuosity ---\n",
    "    # Tortuosity is defined as road_length divided by the straight-line distance.\n",
    "    # To avoid division by zero, we use np.where to set tortuosity to NaN when straight_distance is 0.\n",
    "\n",
    "    roads_with_both['tortuosity'] = np.where(\n",
    "        roads_with_both['straight_distance'] > 0,\n",
    "        roads_with_both['straight_distance']/ roads_with_both['length'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    return roads_with_both\n",
    "\n",
    "# --- Optionally: Check Summary Statistics ---\n",
    "print(roads_with_both['tortuosity'].describe())\n",
    "\n",
    "# The resulting roads_with_both GeoDataFrame now has a 'tortuosity' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roads_with_both' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mroads_with_both\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roads_with_both' is not defined"
     ]
    }
   ],
   "source": [
    "roads_with_both.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subdivisions2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
