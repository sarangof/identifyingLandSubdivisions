{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City count: 2\n"
     ]
    }
   ],
   "source": [
    "YOUR_NAME = 'sara'\n",
    "\n",
    "AWS_PROFILE = 'cities'\n",
    "\n",
    "\n",
    "# List of cities to process\n",
    "cities = [\"Belo Horizonte\", \"Campinas\"]#, \"Bogota\", \"Nairobi\", \"Bamako\", \n",
    "        #\"Lagos\", \"Accra\", \"Abidjan\", \"Mogadishu\", \"Cape Town\", \n",
    "        #\"Maputo\", \"Luanda\"]\n",
    "\n",
    "test_cities = [\"Belo Horizonte\"]\n",
    "#cities = test_cities\n",
    "\n",
    "cities = [city.replace(' ', '_') for city in cities]\n",
    "\n",
    "number_of_cities = len(cities)\n",
    "\n",
    "print(f'City count: {number_of_cities}')\n",
    "\n",
    "grid_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = \"s3://wri-cities-sandbox/identifyingLandSubdivisions/data\"\n",
    "INPUT_PATH = f'{MAIN_PATH}/input'\n",
    "CITY_INFO_PATH = f'{INPUT_PATH}/city_info'\n",
    "EXTENTS_PATH = f'{CITY_INFO_PATH}/extents'\n",
    "BUILDINGS_PATH = f'{INPUT_PATH}/buildings'\n",
    "ROADS_PATH = f'{INPUT_PATH}/roads'\n",
    "INTERSECTIONS_PATH = f'{INPUT_PATH}/intersections'\n",
    "GRIDS_PATH = f'{INPUT_PATH}/city_info/grids'\n",
    "OUTPUT_PATH = f'{MAIN_PATH}/output'\n",
    "OUTPUT_PATH_CSV = f'{OUTPUT_PATH}/csv'\n",
    "OUTPUT_PATH_RASTER = f'{OUTPUT_PATH}/raster'\n",
    "OUTPUT_PATH_PNG = f'{OUTPUT_PATH}/png'\n",
    "OUTPUT_PATH_RAW = f'{OUTPUT_PATH}/raw_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'RH7N9HN1HFY8VG25',\n",
       "  'HostId': 'v1pqtD9DwMu5fbNbpPeq4Rpt897BhAD6VaJLfaeLdqLg6O0Njygy+dS/2UEIUvjOS8kTsrkuj3g=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'v1pqtD9DwMu5fbNbpPeq4Rpt897BhAD6VaJLfaeLdqLg6O0Njygy+dS/2UEIUvjOS8kTsrkuj3g=',\n",
       "   'x-amz-request-id': 'RH7N9HN1HFY8VG25',\n",
       "   'date': 'Wed, 12 Mar 2025 00:21:36 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'aft-sandbox-540362055257',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 13, 15, 12, 20, tzinfo=tzutc())},\n",
       "  {'Name': 'amplify-citiesindicatorsapi-dev-10508-deployment',\n",
       "   'CreationDate': datetime.datetime(2023, 8, 30, 5, 5, 13, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-dev-sandbox',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 7, 23, 18, 12, tzinfo=tzutc())},\n",
       "  {'Name': 'cities-heat',\n",
       "   'CreationDate': datetime.datetime(2023, 6, 1, 13, 22, 1, tzinfo=tzutc())},\n",
       "  {'Name': 'era5-brazil',\n",
       "   'CreationDate': datetime.datetime(2025, 2, 15, 19, 51, 14, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-athena-us-west-2',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 12, 18, 45, 11, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-climate-hazards',\n",
       "   'CreationDate': datetime.datetime(2024, 1, 3, 16, 57, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-data-api',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 16, 8, 53, 31, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-heat',\n",
       "   'CreationDate': datetime.datetime(2024, 3, 25, 15, 46, 55, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-indicators',\n",
       "   'CreationDate': datetime.datetime(2024, 5, 13, 15, 50, 58, tzinfo=tzutc())},\n",
       "  {'Name': 'wri-cities-sandbox',\n",
       "   'CreationDate': datetime.datetime(2024, 7, 27, 0, 51, 38, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'aws-cities',\n",
       "  'ID': 'df12253943982d72f60594f06c2cacf9a1ee3a9e738c1649c9fb96e5127f1a5c'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check s3 connection using AWS_PROFILE=CitiesUserPermissionSet profile \n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# export CitiesUserPermissionSet profile to use in the next cells\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = AWS_PROFILE\n",
    "\n",
    "\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-11 19:21:46,556][INFO    ][coiled] Fetching latest package priorities...\n",
      "[2025-03-11 19:21:46,557][INFO    ][coiled.package_sync] Resolving your local subdivisions2 Python environment...\n",
      "[2025-03-11 19:21:47,471][INFO    ][coiled.package_sync] Scanning 442 conda packages...\n",
      "[2025-03-11 19:21:47,479][INFO    ][coiled.package_sync] Scanning 257 python packages...\n",
      "[2025-03-11 19:21:48,591][INFO    ][coiled] Running pip check...\n",
      "[2025-03-11 19:21:50,350][INFO    ][coiled] Validating environment...\n",
      "[2025-03-11 19:21:52,581][INFO    ][coiled] Creating wheel for ~/Documents/Identifying Land Subdivisions/identifyingLandSubdivisions...\n",
      "[2025-03-11 19:21:53,069][WARNING ][coiled.package_sync] Package - libopenvino-intel-cpu-plugin, libopenvino-intel-cpu-plugin~=2025.0.0 has no install candidate for Python 3.12 linux-aarch64 on conda-forge\n",
      "[2025-03-11 19:21:53,074][INFO    ][coiled] Uploading coiled_local_identifyingLandSubdivisions...\n",
      "[2025-03-11 19:21:54,704][INFO    ][coiled] Requesting package sync build...\n",
      "[2025-03-11 19:21:55,571][INFO    ][coiled] Creating Cluster (name: ils-sara, https://cloud.coiled.io/clusters/793315?account=wri-cities-data ). This usually takes 1-2 minutes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a new Dask client on Coiled. Dashboard is available at https://cluster-tuirq.dask.host/C5sf1UxHnJ4evFtP/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8212' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8213' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8901' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8902' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10462' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10463' coro=<Client._gather.<locals>.wait() done, defined at /Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py:2394> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sarangof/miniconda3/envs/subdivisions2/lib/python3.12/site-packages/distributed/client.py\", line 2403, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    }
   ],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    workspace=\"wri-cities-data\",\n",
    "    name=f'ils-{YOUR_NAME}',\n",
    "    region=\"us-west-2\",\n",
    "    arm=True,\n",
    "    worker_vm_types=\"r8g.xlarge\",\n",
    "    spot_policy=\"spot\",\n",
    "    n_workers=4,\n",
    ")\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(f\"Started a new Dask client on Coiled. Dashboard is available at {client.dashboard_link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas as dgpd\n",
    "from dask import delayed, compute, visualize\n",
    "from dask.diagnostics import ProgressBar\n",
    "%autoreload\n",
    "from citywide_calculation import get_utm_crs\n",
    "from metrics_calculation import calculate_minimum_distance_to_roads_option_B\n",
    "from shapely.geometry import MultiLineString, LineString\n",
    "\n",
    "@delayed\n",
    "def get_epsg(city_name):\n",
    "    urban_extent = f'{EXTENTS_PATH}/{city_name}/{city_name}_urban_extent.geoparquet'\n",
    "    extent = dgpd.read_parquet(urban_extent)\n",
    "    geometry = extent.geometry[0].compute()\n",
    "    epsg = get_utm_crs(geometry)\n",
    "    print(f'{city_name} EPSG: {epsg}')\n",
    "    return epsg\n",
    "\n",
    "@delayed\n",
    "def load_dataset(path, epsg=None):\n",
    "    \"\"\"Load a single parquet dataset\"\"\"\n",
    "    dataset = dgpd.read_parquet(path, npartitions=2)\n",
    "    if epsg:\n",
    "        dataset = dataset.to_crs(epsg=epsg)\n",
    "    return dataset\n",
    "\n",
    "@delayed\n",
    "def row_count(dgdf):\n",
    "    \"\"\"Count the rows in a dataframe\"\"\"\n",
    "    row_count = dgdf.map_partitions(len).compute().sum()\n",
    "\n",
    "    return row_count\n",
    "\n",
    "\n",
    "def test_math(input):\n",
    "    return input + input\n",
    "\n",
    "%autoreload\n",
    "from metrics_groupby import metrics\n",
    "\n",
    "@delayed\n",
    "def metrics(city_name):\n",
    "    grid_cell_count = 0\n",
    "    paths = {\n",
    "        'grid': f'{GRIDS_PATH}/{city_name}/{city_name}_{str(grid_size)}m_grid.geoparquet',\n",
    "        'buildings': f'{BUILDINGS_PATH}/{city_name}/Overture_building_{city_name}.geoparquet',\n",
    "        'roads': f'{ROADS_PATH}/{city_name}/{city_name}_OSM_roads.geoparquet',\n",
    "        'intersections': f'{INTERSECTIONS_PATH}/{city_name}/{city_name}_OSM_intersections.geoparquet'\n",
    "    }\n",
    "    # Get EPSG\n",
    "    epsg = get_epsg(city_name)\n",
    "    # Load grid\n",
    "    grid = load_dataset(paths['grid'], epsg=epsg).compute()\n",
    "    grid['cell_area'] = grid.geometry.area\n",
    "\n",
    "    cells = grid.index.size\n",
    "    grid_cell_count += cells.compute()\n",
    "\n",
    "    # Load buildings and perform relevant calculations on it\n",
    "    buildings = load_dataset(paths['buildings'], epsg=epsg).compute()\n",
    "    buildings['area'] = buildings.geometry.area\n",
    "    joined_buildings = dgpd.sjoin(buildings, grid, predicate='within')  \n",
    "    counts_buildings = joined_buildings.groupby('index_right').size()\n",
    "    grid['n_buildings'] = grid.index.map(counts_buildings).fillna(0).astype(int)\n",
    "    built_area_buildings = joined_buildings.groupby('index_right')['area'].sum()\n",
    "    grid['built_area'] = grid.index.map(built_area_buildings).fillna(0).astype(float)\n",
    "\n",
    "    #total_buildings = row_count(buildings).compute()\n",
    "    #print(total_buildings)\n",
    "    # Load roads\n",
    "    roads = load_dataset(paths['roads'], epsg=epsg).compute()\n",
    "    road_union = roads.unary_union.compute()\n",
    "    # Load intersections\n",
    "    intersections = load_dataset(paths['intersections'], epsg=epsg).compute()\n",
    "    print(type(intersections))\n",
    "    intersections_3plus = intersections[intersections.street_count >= 3]\n",
    "    print(type(intersections_3plus))\n",
    "    intersections_4way = intersections[intersections.street_count == 4]\n",
    "    print(type(intersections_4way))\n",
    "\n",
    "\n",
    "    \n",
    "    buildings['distance_to_road'] = buildings['geometry'].apply(\n",
    "        lambda geom: calculate_minimum_distance_to_roads_option_B(geom, road_union), \n",
    "        meta=('distance_to_road', 'float64')\n",
    "    )\n",
    "    '''\n",
    "    buildings_within_10m_of_buildings = buildings[buildings.distance_to_road <= 20]\n",
    "    joined_buildings_within_10m_of_buildings = dgpd.sjoin(buildings_within_10m_of_buildings, grid, predicate='within')\n",
    "    counts_buildings_within_10m_of_buildings = joined_buildings_within_10m_of_buildings.groupby('index_right').size()\n",
    "    grid['n_buildings_within_10m_of_roads'] = grid.index.map(counts_buildings_within_10m_of_buildings).fillna(0).astype(int)\n",
    "    \n",
    "    joined_buildings_distance_to_road = dgpd.sjoin(buildings['distance_to_road'], grid, predicate='within')\n",
    "    # NOT SURE OF THIS YET\n",
    "    averaged_buildings_distance_to_road = joined_buildings_distance_to_road.groupby('index_right')['distance_to_road'].mean()\n",
    "    '''\n",
    "\n",
    "    joined_intersections_3plus = dgpd.sjoin(intersections_3plus, grid, predicate='within')\n",
    "    counts_intersections_3plus = joined_intersections_3plus.groupby('index_right').size()\n",
    "    grid['intersections_3plus'] = grid.index.map(counts_intersections_3plus).fillna(0).astype(int)\n",
    "\n",
    "    joined_intersections_4way = dgpd.sjoin(intersections_4way, grid, predicate='within')\n",
    "    counts_intersections_4way = joined_intersections_4way.groupby('index_right').size()\n",
    "    grid['intersections_4way'] = grid.index.map(counts_intersections_4way).fillna(0).astype(int)\n",
    "    '''\n",
    "    grid['m1'] = grid['n_buildings_within_10m_of_roads'] / grid['n_buildings']\n",
    "    grid['m2'] = grid.index.map(averaged_buildings_distance_to_road).fillna(0).astype(int)\n",
    "    '''\n",
    "\n",
    "    grid['m4'] = grid['intersections_4way'] / grid['intersections_3plus']\n",
    "\n",
    "\n",
    "    grid['m11'] = grid['n_buildings'] / grid['cell_area'] # Building density\n",
    "    grid['m12'] = grid['built_area'] / grid['cell_area'] # Built area share\n",
    "    grid['m13'] = grid['built_area'] / grid['n_buildings'] # Average building area\n",
    "\n",
    "    path = f'{OUTPUT_PATH_RASTER}/{city_name}/{city_name}_{str(grid_size)}m_grid_{YOUR_NAME}.geoparquet'\n",
    "    grid.to_parquet(path)\n",
    "    return grid_cell_count, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belo_Horizonte', 'Campinas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30188,\n",
       "  's3://wri-cities-sandbox/identifyingLandSubdivisions/data/output/raster/Belo_Horizonte/Belo_Horizonte_200m_grid_sara.geoparquet'),\n",
       " (37752,\n",
       "  's3://wri-cities-sandbox/identifyingLandSubdivisions/data/output/raster/Campinas/Campinas_200m_grid_sara.geoparquet'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cities)\n",
    "\n",
    "# Create delayed tasks for counting\n",
    "grid_calculations = []\n",
    "\n",
    "for city_name in cities:\n",
    "    grid_calc = metrics(city_name, \"chris\", grid_size=grid_size)\n",
    "    grid_calculations.append(grid_calc)\n",
    "\n",
    "#visualize(*grid_calulations)\n",
    "calculated_grids = compute(*grid_calculations)\n",
    "calculated_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grid cells: 462160\n"
     ]
    }
   ],
   "source": [
    "# Sum the total number of grid cells\n",
    "total_grid_cells = sum([grid_cells for grid_cells, path in calculated_grids])\n",
    "print(f'Total grid cells: {total_grid_cells}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subdivisions2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
